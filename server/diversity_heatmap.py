"""
å›ç­”å¤šæ¨£æ€§ç†±åŠ›åœ–è¦–è¦ºåŒ–å·¥å…·
ç”¢ç”Ÿ HTML ç†±åŠ›åœ–ä¾†è§€å¯Ÿå›ç­”çš„é‡è¤‡æ¨¡å¼

åŠŸèƒ½:
1. é–‹é ­ç”¨èªé »ç‡åˆ†æ
2. å•é¡Œå›ç­”å¤šæ¨£æ€§æ’å
3. Persona å€‹åˆ¥åˆ†æ (NEW)
4. N-gram è©é »åˆ†æ (NEW)
5. æ™‚é–“è¶¨å‹¢è¿½è¹¤ (NEW)
"""
import json
import re
from typing import List, Dict, Any, Tuple
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime
from response_analyzer import load_all_responses


# ===== ç¦æ­¢/ç›£æ§/å¥½çš„é–‹é ­è© =====
BANNED_OPENINGS = {'å…¶å¯¦', 'å—¯', 'å“¦', 'æ¬¸', 'é‚£æ™‚å€™'}
MONITOR_OPENINGS = {'ç•¶æ™‚', 'è¨˜å¾—', 'èªªå¯¦è©±', 'å¤§æ¦‚', 'æ€éº¼èªª', 'æœ¬ä¾†', 'è€å¯¦èªª', 'å°±æ˜¯', 'æ˜¯æˆ‘', 'æˆ‘ç¬¬ä¸€æ¬¡'}
GOOD_OPENINGS = {
    'èªªåˆ°é€™å€‹', 'å”‰', 'ä½ çŸ¥é“å—', 'è¬›ä¸€å€‹', 'å¦ç™½èªª', 'è®“æˆ‘æƒ³', 'å¥½ï¼Œ', 'ä¸çŸ¥é“', 'é€™è¦å¾',
    'å»å¹´', 'æœ‰ä¸€æ¬¡', 'å“å‘€', 'å¤©å•Š', 'æˆ‘è·Ÿä½ èªª', 'æ€éº¼èªªå‘¢', 'è€å¯¦è¬›', 'ç°¡å–®èªª', 'ä½ çŒœ'
}

ALL_OPENINGS = list(BANNED_OPENINGS) + list(MONITOR_OPENINGS) + list(GOOD_OPENINGS)


def generate_opening_heatmap_data(responses: List[Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆé–‹é ­ç”¨èªçš„ç†±åŠ›åœ–è³‡æ–™"""
    persona_openings = defaultdict(lambda: defaultdict(int))
    persona_total = defaultdict(int)

    for resp in responses:
        persona = resp['persona_name']
        answer = resp['answer'].strip()[:20]
        persona_total[persona] += 1

        for opening in ALL_OPENINGS:
            if opening in answer:
                persona_openings[persona][opening] += 1

    return {
        'openings': ALL_OPENINGS,
        'personas': list(persona_openings.keys()),
        'data': {
            persona: {
                opening: count / max(persona_total[persona], 1) * 100
                for opening, count in counts.items()
            }
            for persona, counts in persona_openings.items()
        },
        'totals': {
            opening: sum(
                persona_openings[p].get(opening, 0)
                for p in persona_openings
            )
            for opening in ALL_OPENINGS
        }
    }


def generate_question_response_similarity_matrix(responses: List[Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆå•é¡Œ-å›ç­”ç›¸ä¼¼åº¦çŸ©é™£"""
    # æŒ‰å•é¡Œåˆ†çµ„
    question_groups = defaultdict(list)
    for resp in responses:
        q = resp['question'][:50]
        question_groups[q].append(resp)

    # è¨ˆç®—æ¯å€‹å•é¡Œçš„å›ç­”å¤šæ¨£æ€§
    question_diversity = {}
    for question, resps in question_groups.items():
        if len(resps) < 2:
            continue

        # è¨ˆç®—æ‰€æœ‰å›ç­”ä¹‹é–“çš„å­—ç¬¦é‡ç–Š
        total_sim = 0
        count = 0
        for i in range(len(resps)):
            for j in range(i + 1, len(resps)):
                set1 = set(resps[i]['answer'])
                set2 = set(resps[j]['answer'])
                sim = len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0
                total_sim += sim
                count += 1

        avg_sim = total_sim / count if count > 0 else 0
        question_diversity[question] = {
            'response_count': len(resps),
            'avg_similarity': round(avg_sim * 100, 1),
            'diversity_score': round((1 - avg_sim) * 100, 1)
        }

    return question_diversity


# ===== NEW: Persona å€‹åˆ¥åˆ†æ =====
def analyze_persona_style(responses: List[Dict]) -> Dict[str, Dict[str, Any]]:
    """åˆ†ææ¯å€‹ persona çš„å›ç­”é¢¨æ ¼ç‰¹å¾µ"""
    persona_data = defaultdict(lambda: {
        'responses': [],
        'openings_used': Counter(),
        'endings_used': Counter(),
        'avg_length': 0,
        'sentiment_words': {'positive': 0, 'negative': 0},
        'unique_chars': set(),
    })

    positive_words = ['å¥½', 'æ£’', 'æ–¹ä¾¿', 'å¿«é€Ÿ', 'æ¨è–¦', 'æ»¿æ„', 'ä¸éŒ¯', 'å–œæ­¡', 'å®‰å¿ƒ', 'æ”¾å¿ƒ']
    negative_words = ['ç…©', 'æ°£', 'æ…¢', 'è¤‡é›œ', 'éº»ç…©', 'é›£', 'è²´', 'å·®', 'çˆ›', 'è¨å­', 'ç”Ÿæ°£', 'å¤±æœ›']

    for resp in responses:
        persona = resp['persona_name']
        answer = resp['answer'].strip()

        persona_data[persona]['responses'].append(answer)

        # åˆ†æé–‹é ­
        opening = answer[:15]
        for op in ALL_OPENINGS:
            if op in opening:
                persona_data[persona]['openings_used'][op] += 1

        # åˆ†æçµå°¾
        ending = answer[-20:] if len(answer) > 20 else answer
        ending_particles = ['å•¦', 'å§', 'å–”', 'å‘¢', 'è€¶', 'å“ˆå“ˆ', 'å°å§']
        for ep in ending_particles:
            if ep in ending:
                persona_data[persona]['endings_used'][ep] += 1

        # æƒ…æ„Ÿè©
        for word in positive_words:
            persona_data[persona]['sentiment_words']['positive'] += answer.count(word)
        for word in negative_words:
            persona_data[persona]['sentiment_words']['negative'] += answer.count(word)

        # ç”¨å­—å¤šæ¨£æ€§
        persona_data[persona]['unique_chars'].update(set(answer))

    # è¨ˆç®—å¹³å‡é•·åº¦å’Œå¤šæ¨£æ€§æŒ‡æ¨™
    result = {}
    for persona, data in persona_data.items():
        total_len = sum(len(r) for r in data['responses'])
        result[persona] = {
            'response_count': len(data['responses']),
            'avg_length': round(total_len / len(data['responses']), 1) if data['responses'] else 0,
            'top_openings': data['openings_used'].most_common(3),
            'top_endings': data['endings_used'].most_common(3),
            'sentiment_ratio': round(
                data['sentiment_words']['positive'] /
                max(data['sentiment_words']['negative'], 1), 2
            ),
            'unique_char_count': len(data['unique_chars']),
            'banned_opening_count': sum(
                data['openings_used'].get(op, 0) for op in BANNED_OPENINGS
            ),
            'good_opening_count': sum(
                data['openings_used'].get(op, 0) for op in GOOD_OPENINGS
            ),
        }

    return result


# ===== NEW: N-gram åˆ†æ =====
def extract_ngrams(text: str, n: int = 2) -> List[str]:
    """å¾æ–‡å­—ä¸­æå– n-gram"""
    # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    text = re.sub(r'[^\w\s]', '', text)
    # æŒ‰ç©ºç™½æˆ–å­—å…ƒåˆ‡åˆ†ï¼ˆä¸­æ–‡é€å­—ï¼‰
    chars = list(text.replace(' ', ''))
    return [''.join(chars[i:i+n]) for i in range(len(chars) - n + 1)]


def analyze_ngrams(responses: List[Dict], n: int = 3) -> Dict[str, Any]:
    """åˆ†æå›ç­”ä¸­çš„å¸¸è¦‹ n-gram"""
    all_ngrams = Counter()
    opening_ngrams = Counter()  # é–‹é ­ n-gram
    ending_ngrams = Counter()   # çµå°¾ n-gram

    for resp in responses:
        answer = resp['answer'].strip()

        # å…¨æ–‡ n-gram
        ngrams = extract_ngrams(answer, n)
        all_ngrams.update(ngrams)

        # é–‹é ­ n-gram (å‰ 30 å­—)
        opening = answer[:30]
        opening_ngrams.update(extract_ngrams(opening, n))

        # çµå°¾ n-gram (å¾Œ 30 å­—)
        ending = answer[-30:] if len(answer) > 30 else answer
        ending_ngrams.update(extract_ngrams(ending, n))

    return {
        'n': n,
        'top_overall': all_ngrams.most_common(30),
        'top_openings': opening_ngrams.most_common(20),
        'top_endings': ending_ngrams.most_common(20),
    }


def analyze_phrase_patterns(responses: List[Dict]) -> Dict[str, int]:
    """åˆ†æå¸¸è¦‹çŸ­èªæ¨¡å¼"""
    patterns = [
        # é–‹é ­æ¨¡å¼
        (r'^å…¶å¯¦[æˆ‘æ˜¯]', 'ã€Œå…¶å¯¦æˆ‘/æ˜¯...ã€é–‹é ­'),
        (r'^å—¯[ï¼Œ,]', 'ã€Œå—¯ï¼Œã€é–‹é ­'),
        (r'^èªªå¯¦è©±', 'ã€Œèªªå¯¦è©±ã€é–‹é ­'),
        (r'^æ€éº¼èªªå‘¢', 'ã€Œæ€éº¼èªªå‘¢ã€é–‹é ­'),
        # çµå°¾æ¨¡å¼
        (r'å°±é€™æ¨£[å§å•¦]?$', 'ã€Œå°±é€™æ¨£ã€çµå°¾'),
        (r'ç¸½ä¹‹.{0,10}$', 'ã€Œç¸½ä¹‹...ã€çµå°¾'),
        (r'å€¼å¾—[çš„]?$', 'ã€Œå€¼å¾—ã€çµå°¾'),
        (r'å“ˆå“ˆ[å“ˆ]*$', 'ã€Œå“ˆå“ˆã€çµå°¾'),
        # ä¸­é–“æ¨¡å¼
        (r'è·Ÿä½ èªª', 'ä½¿ç”¨ã€Œè·Ÿä½ èªªã€'),
        (r'æˆ‘è¦ºå¾—', 'ä½¿ç”¨ã€Œæˆ‘è¦ºå¾—ã€'),
        (r'ç„¶å¾Œå°±', 'ä½¿ç”¨ã€Œç„¶å¾Œå°±ã€'),
        (r'å¾Œä¾†', 'ä½¿ç”¨ã€Œå¾Œä¾†ã€'),
    ]

    results = {}
    for pattern, name in patterns:
        count = sum(1 for r in responses if re.search(pattern, r['answer']))
        if count > 0:
            results[name] = count

    return dict(sorted(results.items(), key=lambda x: x[1], reverse=True))


# ===== NEW: æ™‚é–“è¶¨å‹¢åˆ†æ =====
def analyze_time_trends(responses: List[Dict]) -> Dict[str, Any]:
    """åˆ†æå›ç­”éš¨æ™‚é–“çš„è®ŠåŒ–è¶¨å‹¢"""
    # æŒ‰æ™‚é–“æ’åº
    dated_responses = []
    for resp in responses:
        ts = resp.get('timestamp', '')
        if ts:
            try:
                # çµ±ä¸€è½‰æˆ naive datetimeï¼ˆç§»é™¤æ™‚å€è³‡è¨Šï¼‰
                dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                if dt.tzinfo is not None:
                    dt = dt.replace(tzinfo=None)
                dated_responses.append((dt, resp))
            except (ValueError, TypeError):
                pass

    if len(dated_responses) < 5:
        return {'error': 'è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ†ææ™‚é–“è¶¨å‹¢'}

    dated_responses.sort(key=lambda x: x[0])

    # åˆ†æˆå‰åŠå’Œå¾ŒåŠ
    mid = len(dated_responses) // 2
    early = [r for _, r in dated_responses[:mid]]
    later = [r for _, r in dated_responses[mid:]]

    def calc_banned_rate(resps):
        count = 0
        for r in resps:
            opening = r['answer'][:15]
            if any(op in opening for op in BANNED_OPENINGS):
                count += 1
        return round(count / len(resps) * 100, 1) if resps else 0

    def calc_avg_length(resps):
        return round(sum(len(r['answer']) for r in resps) / len(resps), 1) if resps else 0

    return {
        'total_responses': len(dated_responses),
        'date_range': {
            'start': dated_responses[0][0].strftime('%Y-%m-%d'),
            'end': dated_responses[-1][0].strftime('%Y-%m-%d'),
        },
        'early_period': {
            'count': len(early),
            'banned_opening_rate': calc_banned_rate(early),
            'avg_length': calc_avg_length(early),
        },
        'later_period': {
            'count': len(later),
            'banned_opening_rate': calc_banned_rate(later),
            'avg_length': calc_avg_length(later),
        },
        'improvement': {
            'banned_opening_change': round(
                calc_banned_rate(early) - calc_banned_rate(later), 1
            ),
            'length_change': round(
                calc_avg_length(later) - calc_avg_length(early), 1
            ),
        }
    }


def generate_html_report(responses: List[Dict]) -> str:
    """ç”Ÿæˆç°¡æ½”çš„å–®é å„€è¡¨æ¿å ±å‘Š"""
    opening_data = generate_opening_heatmap_data(responses)
    time_trends = analyze_time_trends(responses)

    # è¨ˆç®—é—œéµæŒ‡æ¨™
    total = len(responses)
    persona_count = len(set(r['persona_name'] for r in responses))

    # ç¦æ­¢é–‹é ­ä½¿ç”¨çµ±è¨ˆ
    banned_counts = {op: 0 for op in BANNED_OPENINGS}
    good_counts = {op: 0 for op in GOOD_OPENINGS}

    for resp in responses:
        opening = resp['answer'].strip()[:20]
        for op in BANNED_OPENINGS:
            if op in opening:
                banned_counts[op] += 1
        for op in GOOD_OPENINGS:
            if op in opening:
                good_counts[op] += 1

    total_banned = sum(banned_counts.values())
    total_good = sum(good_counts.values())
    banned_rate = round(total_banned / total * 100, 1) if total > 0 else 0
    good_rate = round(total_good / total * 100, 1) if total > 0 else 0

    # æ’åº
    sorted_banned = sorted(banned_counts.items(), key=lambda x: x[1], reverse=True)
    sorted_good = sorted(good_counts.items(), key=lambda x: x[1], reverse=True)

    # æ™‚é–“è¶¨å‹¢
    trend_html = ""
    if 'error' not in time_trends:
        improvement = time_trends['improvement']['banned_opening_change']
        trend_icon = "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰"
        trend_color = "#22c55e" if improvement > 0 else "#ef4444"
        trend_html = f"""
            <div style="background: {'#f0fdf4' if improvement > 0 else '#fef2f2'}; padding: 12px 16px; border-radius: 8px; margin-top: 16px;">
                <span style="color: {trend_color}; font-weight: 600;">{trend_icon} {'æ”¹å–„' if improvement > 0 else 'æƒ¡åŒ–'} {abs(improvement)}%</span>
                <span style="color: #64748b; margin-left: 8px;">vs å‰æœŸ</span>
            </div>
        """

    html = f"""<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å›ç­”å¤šæ¨£æ€§å„€è¡¨æ¿</title>
    <style>
        * {{ box-sizing: border-box; margin: 0; padding: 0; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 24px;
        }}
        .dashboard {{
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 25px 50px -12px rgba(0,0,0,0.25);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
            color: white;
            padding: 32px;
            text-align: center;
        }}
        .header h1 {{
            font-size: 1.5em;
            font-weight: 600;
            margin-bottom: 8px;
        }}
        .header p {{
            color: #94a3b8;
            font-size: 0.9em;
        }}
        .content {{
            padding: 32px;
        }}

        /* ä¸»è¦æŒ‡æ¨™ */
        .metrics {{
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 16px;
            margin-bottom: 32px;
        }}
        .metric {{
            text-align: center;
            padding: 20px;
            background: #f8fafc;
            border-radius: 12px;
        }}
        .metric-value {{
            font-size: 2.5em;
            font-weight: 700;
            color: #1e293b;
        }}
        .metric-value.bad {{ color: #dc2626; }}
        .metric-value.ok {{ color: #f59e0b; }}
        .metric-value.good {{ color: #16a34a; }}
        .metric-label {{
            color: #64748b;
            font-size: 0.85em;
            margin-top: 4px;
        }}

        /* å€å¡Šæ¨™é¡Œ */
        .section-title {{
            font-size: 1em;
            font-weight: 600;
            color: #1e293b;
            margin: 24px 0 16px 0;
            display: flex;
            align-items: center;
            gap: 8px;
        }}

        /* å•é¡Œåˆ—è¡¨ */
        .problem-list {{
            background: #fef2f2;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 24px;
        }}
        .problem-item {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0;
            border-bottom: 1px solid #fecaca;
        }}
        .problem-item:last-child {{ border-bottom: none; }}
        .problem-word {{
            font-weight: 600;
            color: #991b1b;
        }}
        .problem-count {{
            background: #dc2626;
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 600;
        }}

        /* å¥½çš„é–‹é ­ */
        .good-list {{
            background: #f0fdf4;
            border-radius: 12px;
            padding: 20px;
        }}
        .good-item {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0;
            border-bottom: 1px solid #bbf7d0;
        }}
        .good-item:last-child {{ border-bottom: none; }}
        .good-word {{
            font-weight: 600;
            color: #166534;
        }}
        .good-count {{
            background: #16a34a;
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 600;
        }}

        /* å»ºè­° */
        .suggestion {{
            background: #eff6ff;
            border-radius: 12px;
            padding: 20px;
            margin-top: 24px;
        }}
        .suggestion-title {{
            font-weight: 600;
            color: #1e40af;
            margin-bottom: 12px;
        }}
        .suggestion-text {{
            color: #1e3a8a;
            font-size: 0.9em;
            line-height: 1.6;
        }}

        .footer {{
            text-align: center;
            padding: 20px;
            color: #94a3b8;
            font-size: 0.8em;
            border-top: 1px solid #e2e8f0;
        }}
    </style>
</head>
<body>
    <div class="dashboard">
        <div class="header">
            <h1>å›ç­”å¤šæ¨£æ€§å„€è¡¨æ¿</h1>
            <p>{datetime.now().strftime('%Y-%m-%d %H:%M')} Â· {total} å‰‡å›ç­” Â· {persona_count} ä½å—è¨ªè€…</p>
        </div>

        <div class="content">
            <!-- ä¸»è¦æŒ‡æ¨™ -->
            <div class="metrics">
                <div class="metric">
                    <div class="metric-value{' bad' if banned_rate > 30 else ' ok' if banned_rate > 15 else ''}">{banned_rate}%</div>
                    <div class="metric-label">ç¦æ­¢é–‹é ­ä½¿ç”¨ç‡</div>
                </div>
                <div class="metric">
                    <div class="metric-value{' good' if good_rate > 10 else ''}">{good_rate}%</div>
                    <div class="metric-label">å¥½é–‹é ­ä½¿ç”¨ç‡</div>
                </div>
                <div class="metric">
                    <div class="metric-value">{total}</div>
                    <div class="metric-label">ç¸½å›ç­”æ•¸</div>
                </div>
            </div>

            {trend_html}

            <!-- ç¦æ­¢é–‹é ­çµ±è¨ˆ -->
            <div class="section-title">ğŸš« ç¦æ­¢é–‹é ­ï¼ˆéœ€è¦æ¸›å°‘ï¼‰</div>
            <div class="problem-list">
"""

    for word, count in sorted_banned:
        if count > 0:
            pct = round(count / total * 100, 1)
            html += f"""
                <div class="problem-item">
                    <span class="problem-word">ã€Œ{word}ã€</span>
                    <span class="problem-count">{count} æ¬¡ ({pct}%)</span>
                </div>
"""

    html += """
            </div>

            <!-- å¥½çš„é–‹é ­çµ±è¨ˆ -->
            <div class="section-title">âœ… å¥½é–‹é ­ï¼ˆç¹¼çºŒä¿æŒï¼‰</div>
            <div class="good-list">
"""

    for word, count in sorted_good:
        if count > 0:
            pct = round(count / total * 100, 1)
            html += f"""
                <div class="good-item">
                    <span class="good-word">ã€Œ{word}ã€</span>
                    <span class="good-count">{count} æ¬¡ ({pct}%)</span>
                </div>
"""

    if total_good == 0:
        html += """
                <div style="color: #64748b; text-align: center; padding: 20px;">
                    å°šæœªåµæ¸¬åˆ°å¥½çš„é–‹é ­ç”¨èª
                </div>
"""

    html += """
            </div>

            <!-- å»ºè­° -->
            <div class="suggestion">
                <div class="suggestion-title">ğŸ’¡ ä¸‹ä¸€æ­¥</div>
                <div class="suggestion-text">
                    é‡æ–°ç”Ÿæˆè¨ªè«‡å…§å®¹å¾Œï¼Œå†æ¬¡åŸ·è¡Œæ­¤å ±å‘Šæª¢æŸ¥æ”¹å–„æ•ˆæœã€‚<br>
                    ç›®æ¨™ï¼šç¦æ­¢é–‹é ­ä½¿ç”¨ç‡ < 10%ï¼Œå¥½é–‹é ­ä½¿ç”¨ç‡ > 20%
                </div>
            </div>
        </div>

        <div class="footer">
            Response Diversity Analyzer v3.0
        </div>
    </div>
</body>
</html>
"""

    return html


def save_report(output_path: str = "server/diversity_report.html"):
    """ç”Ÿæˆä¸¦å„²å­˜å ±å‘Š"""
    responses = load_all_responses()

    if not responses:
        print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•å›ç­”è³‡æ–™")
        return

    html = generate_html_report(responses)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html)

    print(f"âœ… å ±å‘Šå·²å„²å­˜è‡³: {output_path}")
    print(f"   è«‹åœ¨ç€è¦½å™¨ä¸­é–‹å•ŸæŸ¥çœ‹ç†±åŠ›åœ–")


if __name__ == "__main__":
    save_report()
