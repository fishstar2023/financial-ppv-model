"""
å›ç­”å¤šæ¨£æ€§ç†±åŠ›åœ–è¦–è¦ºåŒ–å·¥å…·
ç”¢ç”Ÿ HTML ç†±åŠ›åœ–ä¾†è§€å¯Ÿå›ç­”çš„é‡è¤‡æ¨¡å¼

åŠŸèƒ½:
1. é–‹é ­ç”¨èªé »ç‡åˆ†æ
2. å•é¡Œå›ç­”å¤šæ¨£æ€§æ’å
3. Persona å€‹åˆ¥åˆ†æ (NEW)
4. N-gram è©é »åˆ†æ (NEW)
5. æ™‚é–“è¶¨å‹¢è¿½è¹¤ (NEW)
"""
import json
import re
from typing import List, Dict, Any, Tuple
from pathlib import Path
from collections import defaultdict, Counter
from datetime import datetime
from response_analyzer import load_all_responses


# ===== ç¦æ­¢/ç›£æ§/å¥½çš„é–‹é ­è© =====
BANNED_OPENINGS = {'å…¶å¯¦', 'å—¯', 'å“¦', 'æ¬¸', 'é‚£æ™‚å€™'}
MONITOR_OPENINGS = {'ç•¶æ™‚', 'è¨˜å¾—', 'èªªå¯¦è©±', 'å¤§æ¦‚', 'æ€éº¼èªª', 'æœ¬ä¾†', 'è€å¯¦èªª', 'å°±æ˜¯', 'æ˜¯æˆ‘', 'æˆ‘ç¬¬ä¸€æ¬¡'}
GOOD_OPENINGS = {'èªªåˆ°é€™å€‹', 'å”‰', 'ä½ çŸ¥é“å—', 'è¬›ä¸€å€‹', 'å¦ç™½èªª', 'è®“æˆ‘æƒ³', 'å¥½ï¼Œ', 'ä¸çŸ¥é“', 'é€™è¦å¾'}

ALL_OPENINGS = list(BANNED_OPENINGS) + list(MONITOR_OPENINGS) + list(GOOD_OPENINGS)


def generate_opening_heatmap_data(responses: List[Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆé–‹é ­ç”¨èªçš„ç†±åŠ›åœ–è³‡æ–™"""
    persona_openings = defaultdict(lambda: defaultdict(int))
    persona_total = defaultdict(int)

    for resp in responses:
        persona = resp['persona_name']
        answer = resp['answer'].strip()[:20]
        persona_total[persona] += 1

        for opening in ALL_OPENINGS:
            if opening in answer:
                persona_openings[persona][opening] += 1

    return {
        'openings': ALL_OPENINGS,
        'personas': list(persona_openings.keys()),
        'data': {
            persona: {
                opening: count / max(persona_total[persona], 1) * 100
                for opening, count in counts.items()
            }
            for persona, counts in persona_openings.items()
        },
        'totals': {
            opening: sum(
                persona_openings[p].get(opening, 0)
                for p in persona_openings
            )
            for opening in ALL_OPENINGS
        }
    }


def generate_question_response_similarity_matrix(responses: List[Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆå•é¡Œ-å›ç­”ç›¸ä¼¼åº¦çŸ©é™£"""
    # æŒ‰å•é¡Œåˆ†çµ„
    question_groups = defaultdict(list)
    for resp in responses:
        q = resp['question'][:50]
        question_groups[q].append(resp)

    # è¨ˆç®—æ¯å€‹å•é¡Œçš„å›ç­”å¤šæ¨£æ€§
    question_diversity = {}
    for question, resps in question_groups.items():
        if len(resps) < 2:
            continue

        # è¨ˆç®—æ‰€æœ‰å›ç­”ä¹‹é–“çš„å­—ç¬¦é‡ç–Š
        total_sim = 0
        count = 0
        for i in range(len(resps)):
            for j in range(i + 1, len(resps)):
                set1 = set(resps[i]['answer'])
                set2 = set(resps[j]['answer'])
                sim = len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0
                total_sim += sim
                count += 1

        avg_sim = total_sim / count if count > 0 else 0
        question_diversity[question] = {
            'response_count': len(resps),
            'avg_similarity': round(avg_sim * 100, 1),
            'diversity_score': round((1 - avg_sim) * 100, 1)
        }

    return question_diversity


# ===== NEW: Persona å€‹åˆ¥åˆ†æ =====
def analyze_persona_style(responses: List[Dict]) -> Dict[str, Dict[str, Any]]:
    """åˆ†ææ¯å€‹ persona çš„å›ç­”é¢¨æ ¼ç‰¹å¾µ"""
    persona_data = defaultdict(lambda: {
        'responses': [],
        'openings_used': Counter(),
        'endings_used': Counter(),
        'avg_length': 0,
        'sentiment_words': {'positive': 0, 'negative': 0},
        'unique_chars': set(),
    })

    positive_words = ['å¥½', 'æ£’', 'æ–¹ä¾¿', 'å¿«é€Ÿ', 'æ¨è–¦', 'æ»¿æ„', 'ä¸éŒ¯', 'å–œæ­¡', 'å®‰å¿ƒ', 'æ”¾å¿ƒ']
    negative_words = ['ç…©', 'æ°£', 'æ…¢', 'è¤‡é›œ', 'éº»ç…©', 'é›£', 'è²´', 'å·®', 'çˆ›', 'è¨å­', 'ç”Ÿæ°£', 'å¤±æœ›']

    for resp in responses:
        persona = resp['persona_name']
        answer = resp['answer'].strip()

        persona_data[persona]['responses'].append(answer)

        # åˆ†æé–‹é ­
        opening = answer[:15]
        for op in ALL_OPENINGS:
            if op in opening:
                persona_data[persona]['openings_used'][op] += 1

        # åˆ†æçµå°¾
        ending = answer[-20:] if len(answer) > 20 else answer
        ending_particles = ['å•¦', 'å§', 'å–”', 'å‘¢', 'è€¶', 'å“ˆå“ˆ', 'å°å§']
        for ep in ending_particles:
            if ep in ending:
                persona_data[persona]['endings_used'][ep] += 1

        # æƒ…æ„Ÿè©
        for word in positive_words:
            persona_data[persona]['sentiment_words']['positive'] += answer.count(word)
        for word in negative_words:
            persona_data[persona]['sentiment_words']['negative'] += answer.count(word)

        # ç”¨å­—å¤šæ¨£æ€§
        persona_data[persona]['unique_chars'].update(set(answer))

    # è¨ˆç®—å¹³å‡é•·åº¦å’Œå¤šæ¨£æ€§æŒ‡æ¨™
    result = {}
    for persona, data in persona_data.items():
        total_len = sum(len(r) for r in data['responses'])
        result[persona] = {
            'response_count': len(data['responses']),
            'avg_length': round(total_len / len(data['responses']), 1) if data['responses'] else 0,
            'top_openings': data['openings_used'].most_common(3),
            'top_endings': data['endings_used'].most_common(3),
            'sentiment_ratio': round(
                data['sentiment_words']['positive'] /
                max(data['sentiment_words']['negative'], 1), 2
            ),
            'unique_char_count': len(data['unique_chars']),
            'banned_opening_count': sum(
                data['openings_used'].get(op, 0) for op in BANNED_OPENINGS
            ),
            'good_opening_count': sum(
                data['openings_used'].get(op, 0) for op in GOOD_OPENINGS
            ),
        }

    return result


# ===== NEW: N-gram åˆ†æ =====
def extract_ngrams(text: str, n: int = 2) -> List[str]:
    """å¾æ–‡å­—ä¸­æå– n-gram"""
    # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    text = re.sub(r'[^\w\s]', '', text)
    # æŒ‰ç©ºç™½æˆ–å­—å…ƒåˆ‡åˆ†ï¼ˆä¸­æ–‡é€å­—ï¼‰
    chars = list(text.replace(' ', ''))
    return [''.join(chars[i:i+n]) for i in range(len(chars) - n + 1)]


def analyze_ngrams(responses: List[Dict], n: int = 3) -> Dict[str, Any]:
    """åˆ†æå›ç­”ä¸­çš„å¸¸è¦‹ n-gram"""
    all_ngrams = Counter()
    opening_ngrams = Counter()  # é–‹é ­ n-gram
    ending_ngrams = Counter()   # çµå°¾ n-gram

    for resp in responses:
        answer = resp['answer'].strip()

        # å…¨æ–‡ n-gram
        ngrams = extract_ngrams(answer, n)
        all_ngrams.update(ngrams)

        # é–‹é ­ n-gram (å‰ 30 å­—)
        opening = answer[:30]
        opening_ngrams.update(extract_ngrams(opening, n))

        # çµå°¾ n-gram (å¾Œ 30 å­—)
        ending = answer[-30:] if len(answer) > 30 else answer
        ending_ngrams.update(extract_ngrams(ending, n))

    return {
        'n': n,
        'top_overall': all_ngrams.most_common(30),
        'top_openings': opening_ngrams.most_common(20),
        'top_endings': ending_ngrams.most_common(20),
    }


def analyze_phrase_patterns(responses: List[Dict]) -> Dict[str, int]:
    """åˆ†æå¸¸è¦‹çŸ­èªæ¨¡å¼"""
    patterns = [
        # é–‹é ­æ¨¡å¼
        (r'^å…¶å¯¦[æˆ‘æ˜¯]', 'ã€Œå…¶å¯¦æˆ‘/æ˜¯...ã€é–‹é ­'),
        (r'^å—¯[ï¼Œ,]', 'ã€Œå—¯ï¼Œã€é–‹é ­'),
        (r'^èªªå¯¦è©±', 'ã€Œèªªå¯¦è©±ã€é–‹é ­'),
        (r'^æ€éº¼èªªå‘¢', 'ã€Œæ€éº¼èªªå‘¢ã€é–‹é ­'),
        # çµå°¾æ¨¡å¼
        (r'å°±é€™æ¨£[å§å•¦]?$', 'ã€Œå°±é€™æ¨£ã€çµå°¾'),
        (r'ç¸½ä¹‹.{0,10}$', 'ã€Œç¸½ä¹‹...ã€çµå°¾'),
        (r'å€¼å¾—[çš„]?$', 'ã€Œå€¼å¾—ã€çµå°¾'),
        (r'å“ˆå“ˆ[å“ˆ]*$', 'ã€Œå“ˆå“ˆã€çµå°¾'),
        # ä¸­é–“æ¨¡å¼
        (r'è·Ÿä½ èªª', 'ä½¿ç”¨ã€Œè·Ÿä½ èªªã€'),
        (r'æˆ‘è¦ºå¾—', 'ä½¿ç”¨ã€Œæˆ‘è¦ºå¾—ã€'),
        (r'ç„¶å¾Œå°±', 'ä½¿ç”¨ã€Œç„¶å¾Œå°±ã€'),
        (r'å¾Œä¾†', 'ä½¿ç”¨ã€Œå¾Œä¾†ã€'),
    ]

    results = {}
    for pattern, name in patterns:
        count = sum(1 for r in responses if re.search(pattern, r['answer']))
        if count > 0:
            results[name] = count

    return dict(sorted(results.items(), key=lambda x: x[1], reverse=True))


# ===== NEW: æ™‚é–“è¶¨å‹¢åˆ†æ =====
def analyze_time_trends(responses: List[Dict]) -> Dict[str, Any]:
    """åˆ†æå›ç­”éš¨æ™‚é–“çš„è®ŠåŒ–è¶¨å‹¢"""
    # æŒ‰æ™‚é–“æ’åº
    dated_responses = []
    for resp in responses:
        ts = resp.get('timestamp', '')
        if ts:
            try:
                # çµ±ä¸€è½‰æˆ naive datetimeï¼ˆç§»é™¤æ™‚å€è³‡è¨Šï¼‰
                dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                if dt.tzinfo is not None:
                    dt = dt.replace(tzinfo=None)
                dated_responses.append((dt, resp))
            except (ValueError, TypeError):
                pass

    if len(dated_responses) < 5:
        return {'error': 'è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ†ææ™‚é–“è¶¨å‹¢'}

    dated_responses.sort(key=lambda x: x[0])

    # åˆ†æˆå‰åŠå’Œå¾ŒåŠ
    mid = len(dated_responses) // 2
    early = [r for _, r in dated_responses[:mid]]
    later = [r for _, r in dated_responses[mid:]]

    def calc_banned_rate(resps):
        count = 0
        for r in resps:
            opening = r['answer'][:15]
            if any(op in opening for op in BANNED_OPENINGS):
                count += 1
        return round(count / len(resps) * 100, 1) if resps else 0

    def calc_avg_length(resps):
        return round(sum(len(r['answer']) for r in resps) / len(resps), 1) if resps else 0

    return {
        'total_responses': len(dated_responses),
        'date_range': {
            'start': dated_responses[0][0].strftime('%Y-%m-%d'),
            'end': dated_responses[-1][0].strftime('%Y-%m-%d'),
        },
        'early_period': {
            'count': len(early),
            'banned_opening_rate': calc_banned_rate(early),
            'avg_length': calc_avg_length(early),
        },
        'later_period': {
            'count': len(later),
            'banned_opening_rate': calc_banned_rate(later),
            'avg_length': calc_avg_length(later),
        },
        'improvement': {
            'banned_opening_change': round(
                calc_banned_rate(early) - calc_banned_rate(later), 1
            ),
            'length_change': round(
                calc_avg_length(later) - calc_avg_length(early), 1
            ),
        }
    }


def generate_html_report(responses: List[Dict]) -> str:
    """ç”Ÿæˆå®Œæ•´çš„ HTML ç†±åŠ›åœ–å ±å‘Š"""
    opening_data = generate_opening_heatmap_data(responses)
    question_diversity = generate_question_response_similarity_matrix(responses)
    persona_analysis = analyze_persona_style(responses)
    ngram_analysis = analyze_ngrams(responses, n=3)
    bigram_analysis = analyze_ngrams(responses, n=2)
    phrase_patterns = analyze_phrase_patterns(responses)
    time_trends = analyze_time_trends(responses)

    # è¨ˆç®—é–‹é ­é »ç‡
    opening_freq = {}
    for opening in ALL_OPENINGS:
        count = opening_data['totals'].get(opening, 0)
        opening_freq[opening] = {
            'count': count,
            'percentage': round(count / len(responses) * 100, 1) if responses else 0,
            'status': 'banned' if opening in BANNED_OPENINGS else (
                'monitor' if opening in MONITOR_OPENINGS else 'good'
            )
        }

    # æ’åºå•é¡Œå¤šæ¨£æ€§ï¼ˆä½å¤šæ¨£æ€§å„ªå…ˆï¼‰
    sorted_questions = sorted(
        question_diversity.items(),
        key=lambda x: x[1]['diversity_score']
    )

    html = f"""<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å›ç­”å¤šæ¨£æ€§ç†±åŠ›åœ–åˆ†æ</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #1a1a2e;
            color: #eee;
            padding: 20px;
            max-width: 1600px;
            margin: 0 auto;
        }}
        h1 {{ color: #00d9ff; text-align: center; }}
        h2 {{ color: #ff6b6b; border-bottom: 2px solid #ff6b6b; padding-bottom: 10px; margin-top: 40px; }}
        h3 {{ color: #ffd93d; margin-top: 25px; }}

        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            gap: 15px;
            margin-bottom: 30px;
        }}
        .stat-card {{
            background: #16213e;
            border-radius: 12px;
            padding: 20px;
            text-align: center;
        }}
        .stat-value {{
            font-size: 2.2em;
            font-weight: bold;
            color: #00d9ff;
        }}
        .stat-value.warning {{ color: #ff6b6b; }}
        .stat-value.good {{ color: #4ecdc4; }}
        .stat-label {{
            color: #888;
            margin-top: 5px;
            font-size: 0.9em;
        }}

        .heatmap-container {{
            background: #16213e;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 30px;
            overflow-x: auto;
        }}

        .opening-bar {{
            display: flex;
            align-items: center;
            margin: 8px 0;
        }}
        .opening-label {{
            width: 100px;
            font-weight: bold;
        }}
        .opening-label.banned {{ color: #ff6b6b; }}
        .opening-label.monitor {{ color: #ffd93d; }}
        .opening-label.good {{ color: #4ecdc4; }}
        .opening-bar-fill {{
            height: 28px;
            border-radius: 4px;
            display: flex;
            align-items: center;
            padding-left: 10px;
            color: #000;
            font-weight: bold;
            font-size: 0.9em;
        }}
        .bar-high {{ background: linear-gradient(90deg, #ff6b6b, #ff8e8e); }}
        .bar-medium {{ background: linear-gradient(90deg, #ffd93d, #ffe066); }}
        .bar-low {{ background: linear-gradient(90deg, #4ecdc4, #7ee8e0); }}

        .table-container {{
            overflow-x: auto;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
            font-size: 0.9em;
        }}
        th, td {{
            padding: 10px 12px;
            text-align: left;
            border-bottom: 1px solid #333;
        }}
        th {{
            background: #0f3460;
            color: #00d9ff;
            white-space: nowrap;
        }}
        tr:hover {{
            background: #1f4068;
        }}

        .score-badge {{
            display: inline-block;
            padding: 4px 10px;
            border-radius: 12px;
            font-weight: bold;
            font-size: 0.85em;
        }}
        .score-low {{ background: #ff6b6b; color: #000; }}
        .score-medium {{ background: #ffd93d; color: #000; }}
        .score-high {{ background: #4ecdc4; color: #000; }}

        .insight-box {{
            background: linear-gradient(135deg, #0f3460, #16213e);
            border-left: 4px solid #ff6b6b;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 12px 12px 0;
        }}
        .insight-box h4 {{ color: #ff6b6b; margin-top: 0; }}

        .recommendation {{
            background: linear-gradient(135deg, #1a4d1a, #16213e);
            border-left: 4px solid #4ecdc4;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 12px 12px 0;
        }}
        .recommendation h4 {{ color: #4ecdc4; margin-top: 0; }}

        .trend-box {{
            background: linear-gradient(135deg, #2d1b4e, #16213e);
            border-left: 4px solid #9d4edd;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 12px 12px 0;
        }}
        .trend-box h4 {{ color: #9d4edd; margin-top: 0; }}

        .ngram-cloud {{
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            padding: 15px;
        }}
        .ngram-tag {{
            padding: 6px 12px;
            border-radius: 16px;
            font-size: 0.85em;
        }}
        .ngram-hot {{ background: #ff6b6b; color: #000; }}
        .ngram-warm {{ background: #ffd93d; color: #000; }}
        .ngram-cool {{ background: #4ecdc4; color: #000; }}

        .persona-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 15px;
        }}
        .persona-card {{
            background: #0f3460;
            border-radius: 12px;
            padding: 15px;
        }}
        .persona-name {{
            font-size: 1.1em;
            font-weight: bold;
            color: #00d9ff;
            margin-bottom: 10px;
        }}
        .persona-stat {{
            display: flex;
            justify-content: space-between;
            margin: 5px 0;
            font-size: 0.9em;
        }}
        .persona-stat-label {{ color: #888; }}
        .persona-stat-value {{ font-weight: bold; }}

        .two-column {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }}
        @media (max-width: 900px) {{
            .two-column {{ grid-template-columns: 1fr; }}
        }}

        .nav-tabs {{
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }}
        .nav-tab {{
            padding: 10px 20px;
            background: #16213e;
            border: none;
            border-radius: 8px;
            color: #888;
            cursor: pointer;
            font-size: 0.9em;
        }}
        .nav-tab:hover {{ background: #1f4068; color: #eee; }}
        .nav-tab.active {{ background: #0f3460; color: #00d9ff; }}
    </style>
</head>
<body>
    <h1>ğŸ“Š å›ç­”å¤šæ¨£æ€§ç†±åŠ›åœ–åˆ†æ</h1>
    <p style="text-align: center; color: #888;">Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}</p>

    <div class="stats-grid">
        <div class="stat-card">
            <div class="stat-value">{len(responses)}</div>
            <div class="stat-label">ç¸½å›ç­”æ•¸</div>
        </div>
        <div class="stat-card">
            <div class="stat-value">{len(set(r['persona_name'] for r in responses))}</div>
            <div class="stat-label">å—è¨ªè€…æ•¸</div>
        </div>
        <div class="stat-card">
            <div class="stat-value">{len(question_diversity)}</div>
            <div class="stat-label">ä¸åŒå•é¡Œæ•¸</div>
        </div>
        <div class="stat-card">
            <div class="stat-value{' warning' if opening_freq.get('å…¶å¯¦', {}).get('percentage', 0) > 20 else ''}">{opening_freq.get('å…¶å¯¦', {}).get('percentage', 0):.1f}%</div>
            <div class="stat-label">ğŸš«ã€Œå…¶å¯¦ã€é–‹é ­</div>
        </div>
        <div class="stat-card">
            <div class="stat-value{' warning' if opening_freq.get('å—¯', {}).get('percentage', 0) > 15 else ''}">{opening_freq.get('å—¯', {}).get('percentage', 0):.1f}%</div>
            <div class="stat-label">ğŸš«ã€Œå—¯ã€é–‹é ­</div>
        </div>
    </div>
"""

    # ===== æ™‚é–“è¶¨å‹¢ =====
    if 'error' not in time_trends:
        improvement = time_trends['improvement']['banned_opening_change']
        improvement_class = 'good' if improvement > 0 else 'warning'
        html += f"""
    <div class="trend-box">
        <h4>ğŸ“ˆ æ™‚é–“è¶¨å‹¢åˆ†æ</h4>
        <p>è³‡æ–™æœŸé–“: {time_trends['date_range']['start']} ~ {time_trends['date_range']['end']}</p>
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">{time_trends['early_period']['banned_opening_rate']}%</div>
                <div class="stat-label">å‰æœŸç¦æ­¢é–‹é ­ç‡<br>({time_trends['early_period']['count']} å‰‡)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{time_trends['later_period']['banned_opening_rate']}%</div>
                <div class="stat-label">å¾ŒæœŸç¦æ­¢é–‹é ­ç‡<br>({time_trends['later_period']['count']} å‰‡)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value {improvement_class}">{'+' if improvement > 0 else ''}{improvement}%</div>
                <div class="stat-label">{'æ”¹å–„å¹…åº¦ âœ“' if improvement > 0 else 'æƒ¡åŒ–å¹…åº¦ âœ—'}</div>
            </div>
        </div>
    </div>
"""

    # ===== é–‹é ­ç”¨èªåˆ†æ =====
    html += """
    <h2>ğŸ”¤ é–‹é ­ç”¨èªé »ç‡åˆ†æ</h2>
    <div class="heatmap-container">
        <p style="color: #888;">ğŸš« ç´…è‰² = å·²ç¦æ­¢ | âš ï¸ é»ƒè‰² = ç›£æ§ä¸­ | âœ… ç¶ è‰² = å¥½çš„é–‹é ­</p>
"""

    sorted_openings = sorted(opening_freq.items(), key=lambda x: x[1]['count'], reverse=True)
    for opening, data in sorted_openings:
        if data['count'] == 0:
            continue
        pct = data['percentage']
        status = data['status']
        bar_class = 'bar-high' if status == 'banned' else ('bar-medium' if status == 'monitor' else 'bar-low')
        label_class = status
        width = min(pct * 3, 100)

        html += f"""
        <div class="opening-bar">
            <div class="opening-label {label_class}">ã€Œ{opening}ã€</div>
            <div class="opening-bar-fill {bar_class}" style="width: {width}%;">
                {data['count']} æ¬¡ ({pct}%)
            </div>
        </div>
"""

    html += """
    </div>
"""

    # ===== N-gram è©é »é›² =====
    html += """
    <h2>ğŸ”  å¸¸è¦‹è©çµ„åˆ†æ (N-gram)</h2>
    <div class="two-column">
        <div class="heatmap-container">
            <h3>é–‹é ­å¸¸è¦‹ 3-gram</h3>
            <div class="ngram-cloud">
"""
    for ngram, count in ngram_analysis['top_openings'][:15]:
        tag_class = 'ngram-hot' if count > 20 else ('ngram-warm' if count > 10 else 'ngram-cool')
        html += f'<span class="ngram-tag {tag_class}">{ngram} ({count})</span>\n'

    html += """
            </div>
        </div>
        <div class="heatmap-container">
            <h3>çµå°¾å¸¸è¦‹ 3-gram</h3>
            <div class="ngram-cloud">
"""
    for ngram, count in ngram_analysis['top_endings'][:15]:
        tag_class = 'ngram-hot' if count > 20 else ('ngram-warm' if count > 10 else 'ngram-cool')
        html += f'<span class="ngram-tag {tag_class}">{ngram} ({count})</span>\n'

    html += """
            </div>
        </div>
    </div>
"""

    # ===== çŸ­èªæ¨¡å¼ =====
    if phrase_patterns:
        html += """
    <div class="heatmap-container">
        <h3>å¸¸è¦‹çŸ­èªæ¨¡å¼</h3>
        <div class="table-container">
            <table>
                <thead><tr><th>æ¨¡å¼</th><th>å‡ºç¾æ¬¡æ•¸</th><th>ä½”æ¯”</th></tr></thead>
                <tbody>
"""
        for pattern, count in list(phrase_patterns.items())[:10]:
            pct = round(count / len(responses) * 100, 1)
            html += f"<tr><td>{pattern}</td><td>{count}</td><td>{pct}%</td></tr>\n"

        html += """
                </tbody>
            </table>
        </div>
    </div>
"""

    # ===== Persona å€‹åˆ¥åˆ†æ =====
    html += """
    <h2>ğŸ‘¤ Persona å€‹åˆ¥åˆ†æ</h2>
    <div class="persona-grid">
"""
    # æŒ‰ç¦æ­¢é–‹é ­æ•¸é‡æ’åºï¼ˆå•é¡Œæœ€å¤§çš„åœ¨å‰é¢ï¼‰
    sorted_personas = sorted(
        persona_analysis.items(),
        key=lambda x: x[1]['banned_opening_count'],
        reverse=True
    )

    for persona_name, data in sorted_personas[:12]:
        banned_rate = round(data['banned_opening_count'] / max(data['response_count'], 1) * 100, 1)
        good_rate = round(data['good_opening_count'] / max(data['response_count'], 1) * 100, 1)
        badge_class = 'score-low' if banned_rate > 50 else ('score-medium' if banned_rate > 30 else 'score-high')

        html += f"""
        <div class="persona-card">
            <div class="persona-name">{persona_name}</div>
            <div class="persona-stat">
                <span class="persona-stat-label">å›ç­”æ•¸</span>
                <span class="persona-stat-value">{data['response_count']}</span>
            </div>
            <div class="persona-stat">
                <span class="persona-stat-label">å¹³å‡é•·åº¦</span>
                <span class="persona-stat-value">{data['avg_length']} å­—</span>
            </div>
            <div class="persona-stat">
                <span class="persona-stat-label">ğŸš« ç¦æ­¢é–‹é ­ä½¿ç”¨ç‡</span>
                <span class="persona-stat-value"><span class="score-badge {badge_class}">{banned_rate}%</span></span>
            </div>
            <div class="persona-stat">
                <span class="persona-stat-label">âœ… å¥½é–‹é ­ä½¿ç”¨ç‡</span>
                <span class="persona-stat-value">{good_rate}%</span>
            </div>
            <div class="persona-stat">
                <span class="persona-stat-label">æ­£/è² æƒ…æ„Ÿæ¯”</span>
                <span class="persona-stat-value">{data['sentiment_ratio']}</span>
            </div>
            <div class="persona-stat">
                <span class="persona-stat-label">ç”¨å­—è±å¯Œåº¦</span>
                <span class="persona-stat-value">{data['unique_char_count']} å­—</span>
            </div>
        </div>
"""

    html += """
    </div>
"""

    # ===== å•é¡Œå¤šæ¨£æ€§æ’å =====
    html += """
    <h2>ğŸ“‹ å•é¡Œå›ç­”å¤šæ¨£æ€§æ’å</h2>
    <div class="heatmap-container">
        <p style="color: #888;">å¤šæ¨£æ€§åˆ†æ•¸è¶Šä½ = å›ç­”è¶Šç›¸ä¼¼ï¼ˆéœ€è¦æ”¹é€²ï¼‰</p>
        <div class="table-container">
            <table>
                <thead>
                    <tr>
                        <th>å•é¡Œ</th>
                        <th>å›ç­”æ•¸</th>
                        <th>å¹³å‡ç›¸ä¼¼åº¦</th>
                        <th>å¤šæ¨£æ€§åˆ†æ•¸</th>
                    </tr>
                </thead>
                <tbody>
"""

    for question, data in sorted_questions[:15]:
        score = data['diversity_score']
        score_class = 'score-low' if score < 40 else ('score-medium' if score < 60 else 'score-high')

        html += f"""
                    <tr>
                        <td>{question}...</td>
                        <td>{data['response_count']}</td>
                        <td>{data['avg_similarity']}%</td>
                        <td><span class="score-badge {score_class}">{score}</span></td>
                    </tr>
"""

    html += """
                </tbody>
            </table>
        </div>
    </div>
"""

    # ===== é‡è¤‡å›ç­” =====
    html += """
    <h2>ğŸ”„ å®Œå…¨ç›¸åŒçš„å›ç­”</h2>
    <div class="heatmap-container">
        <p style="color: #ff6b6b;">é€™äº›å›ç­”å®Œå…¨ç›¸åŒï¼Œè¡¨ç¤ºå¯èƒ½æœ‰ç·©å­˜å•é¡Œæˆ– prompt ä¸å¤ éš¨æ©Ÿ</p>
"""

    answer_hash = defaultdict(list)
    for resp in responses:
        key = resp['answer'][:100]
        answer_hash[key].append(resp)

    duplicates = [(k, v) for k, v in answer_hash.items() if len(v) > 1]

    if duplicates:
        html += "<ul>\n"
        for key, resps in duplicates[:10]:
            personas = [r['persona_name'] for r in resps]
            question = resps[0]['question'][:40]
            html += f"""
            <li>
                <strong>å•é¡Œ:</strong> {question}...<br>
                <strong>å—è¨ªè€…:</strong> {', '.join(personas)}<br>
                <strong>å›ç­”é è¦½:</strong> {key}...
            </li>
"""
        html += "</ul>\n"
    else:
        html += "<p style='color: #4ecdc4;'>âœ… æœªç™¼ç¾å®Œå…¨ç›¸åŒçš„å›ç­”</p>\n"

    html += """
    </div>
"""

    # ===== æ”¹é€²å»ºè­° =====
    html += """
    <div class="recommendation">
        <h4>ğŸ’¡ æ”¹é€²å»ºè­°</h4>
        <ol>
            <li><strong>æ¸›å°‘å›ºå®šé–‹é ­</strong>ï¼šåœ¨ prompt ä¸­æ˜ç¢ºç¦æ­¢ã€Œå…¶å¯¦ã€ã€Œå—¯ã€ç­‰é«˜é »é–‹é ­è©</li>
            <li><strong>å¢åŠ é–‹é ­è®ŠåŒ–</strong>ï¼šæä¾›æ›´å¤šæ¨£çš„é–‹é ­æ¨¡æ¿è®“ AI é¸æ“‡</li>
            <li><strong>å¼·åŒ–å€‹æ€§å·®ç•°</strong>ï¼šä¸åŒ persona æ‡‰æœ‰æ˜é¡¯ä¸åŒçš„èªªè©±é¢¨æ ¼</li>
            <li><strong>æª¢æŸ¥ç·©å­˜æ©Ÿåˆ¶</strong>ï¼šç›¸ä¼¼åº¦ 100% çš„å›ç­”å¯èƒ½æ˜¯ç·©å­˜å•é¡Œ</li>
            <li><strong>æŒçºŒç›£æ§</strong>ï¼šå®šæœŸé‡æ–°åŸ·è¡Œæ­¤å ±å‘Šï¼Œè¿½è¹¤æ”¹é€²æ•ˆæœ</li>
        </ol>
    </div>

    <footer style="text-align: center; color: #666; margin-top: 40px; padding: 20px;">
        Generated by Response Diversity Analyzer v2.0
    </footer>
</body>
</html>
"""

    return html


def save_report(output_path: str = "server/diversity_report.html"):
    """ç”Ÿæˆä¸¦å„²å­˜å ±å‘Š"""
    responses = load_all_responses()

    if not responses:
        print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•å›ç­”è³‡æ–™")
        return

    html = generate_html_report(responses)

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html)

    print(f"âœ… å ±å‘Šå·²å„²å­˜è‡³: {output_path}")
    print(f"   è«‹åœ¨ç€è¦½å™¨ä¸­é–‹å•ŸæŸ¥çœ‹ç†±åŠ›åœ–")


if __name__ == "__main__":
    save_report()
