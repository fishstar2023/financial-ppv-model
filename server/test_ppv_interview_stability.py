#!/usr/bin/env python3
"""
PPV æ¥µç«¯æ¡ˆä¾‹è¨ªè«‡ç©©å®šæ€§æ¸¬è©¦ v2
æ¸¬è©¦æ¥µç«¯ persona åœ¨è¨ªè«‡æ™‚çš„å›ç­”å“è³ªèˆ‡ç©©å®šæ€§

æ¸¬è©¦é‡é»ï¼š
1. æ¥µç«¯äººæ ¼çš„å›ç­”æ˜¯å¦ç¬¦åˆå…¶è¨­å®š
2. PPV æ¬„ä½ (verbosity, emotion_expression ç­‰) æ˜¯å¦å½±éŸ¿å›ç­”é¢¨æ ¼
3. ä¸åŒæ¥µç«¯äººæ ¼ä¹‹é–“çš„å›ç­”å·®ç•°æ€§
4. å›ç­”é•·åº¦æ˜¯å¦å— language_style.verbosity å½±éŸ¿
"""

import os
import sys
import json
import re
from pathlib import Path
from collections import Counter

# æ·»åŠ  server ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from vietnam_interview_agent import interview_vietnam_persona
from test_ppv_extreme_cases import (
    create_homogeneous_personas,
    create_polarized_personas,
    create_random_extreme_personas,
    create_perfect_diversity_personas
)


# æ¸¬è©¦å•é¡Œé›†
TEST_QUESTIONS = [
    {
        "question": "è«‹æè¿°ä¸€ä¸‹ä½ ä¸Šæ¬¡è³¼è²·æ—…éŠä¿éšªçš„ç¶“é©—",
        "sub_questions": ["æ˜¯ä»€éº¼è®“ä½ æ±ºå®šè³¼è²·ï¼Ÿ", "éç¨‹ä¸­æœ‰é‡åˆ°ä»€éº¼å›°é›£å—ï¼Ÿ"]
    },
    {
        "question": "å¦‚æœä½ åœ¨æ—…é€”ä¸­é‡åˆ°ç·Šæ€¥é†«ç™‚ç‹€æ³ï¼Œä½ æœƒæ€éº¼åšï¼Ÿ",
        "sub_questions": ["ä½ æœƒå…ˆè¯ç¹«èª°ï¼Ÿ", "ä½ å°ç†è³ æµç¨‹æœ‰ä»€éº¼äº†è§£ï¼Ÿ"]
    },
    {
        "question": "ä½ èªç‚ºæ—…éŠä¿éšªæœ€é‡è¦çš„ä¿éšœæ˜¯ä»€éº¼ï¼Ÿç‚ºä»€éº¼ï¼Ÿ",
        "sub_questions": []
    }
]


def create_extreme_test_personas():
    """å»ºç«‹ç”¨æ–¼æ¸¬è©¦çš„æ¥µç«¯ persona"""

    # 1. æ¥µç«¯é«˜é¢¨éšªå°‹æ±‚è€…
    high_risk_seeker = {
        "id": "extreme_high_risk_001",
        "lastName": "Nguyá»…n",
        "gender": "Male",
        "age": 28,
        "occupation": "Startup Founder",
        "timesOfOverseasTravelInsurance": 1,
        "purchasedBrand": [],
        "purchasedChannels": ["online"],
        "personalBackground": "å‰›å‰µæ¥­ï¼Œå–œæ­¡å†’éšª",
        "big5": {
            "openness": 95,
            "conscientiousness": 20,
            "extraversion": 90,
            "agreeableness": 30,
            "neuroticism": 15
        },
        "risk_profile": {
            "overall": 95,
            "financial": 90,
            "ethical": 60,
            "social": 85,
            "health": 80
        },
        "decision_style": {
            "primary": "spontaneous",
            "secondary": "intuitive",
            "risk_seeking": 95,
            "info_processing": "satisficer",
            "social_preference": "independent"
        },
        "time_preference": {
            "discount_rate": 90,
            "planning_horizon": "short_term",
            "present_vs_future": -80
        },
        "regulatory_focus": {
            "promotion": 95,
            "prevention": 15
        },
        "language_style": {
            "formality": 20,
            "directness": 90,
            "emotion_expression": 85,
            "verbosity": 70
        },
        "emotion_profile": {
            "baseline_valence": 80,
            "emotional_range": 85,
            "stress_response": "fight",
            "recovery_speed": 90
        }
    }

    # 2. æ¥µç«¯ä¿å®ˆè¬¹æ…è€…
    extreme_conservative = {
        "id": "extreme_conservative_001",
        "lastName": "Tráº§n",
        "gender": "Female",
        "age": 55,
        "occupation": "Accountant",
        "timesOfOverseasTravelInsurance": 12,
        "purchasedBrand": ["Báº£o Viá»‡t", "PVI"],
        "purchasedChannels": ["agent", "bank"],
        "personalBackground": "éå¸¸è¬¹æ…ï¼Œå‡¡äº‹ä¸‰æ€",
        "big5": {
            "openness": 15,
            "conscientiousness": 95,
            "extraversion": 20,
            "agreeableness": 75,
            "neuroticism": 85
        },
        "risk_profile": {
            "overall": 5,
            "financial": 5,
            "ethical": 90,
            "social": 10,
            "health": 5
        },
        "decision_style": {
            "primary": "analytical",
            "secondary": "dependent",
            "risk_seeking": 5,
            "info_processing": "maximizer",
            "social_preference": "collaborative"
        },
        "time_preference": {
            "discount_rate": 10,
            "planning_horizon": "long_term",
            "present_vs_future": 90
        },
        "regulatory_focus": {
            "promotion": 10,
            "prevention": 95
        },
        "language_style": {
            "formality": 90,
            "directness": 30,
            "emotion_expression": 25,
            "verbosity": 85
        },
        "emotion_profile": {
            "baseline_valence": 40,
            "emotional_range": 30,
            "stress_response": "freeze",
            "recovery_speed": 25
        }
    }

    # 3. æ¥µç«¯æ‡·ç–‘/è² é¢è€…
    extreme_skeptic = {
        "id": "extreme_skeptic_001",
        "lastName": "LÃª",
        "gender": "Male",
        "age": 42,
        "occupation": "Lawyer",
        "timesOfOverseasTravelInsurance": 5,
        "purchasedBrand": ["Various"],
        "purchasedChannels": ["online"],
        "personalBackground": "æ›¾è¢«ä¿éšªå…¬å¸æ‹’è³ ï¼Œéå¸¸ä¸ä¿¡ä»»",
        "big5": {
            "openness": 40,
            "conscientiousness": 80,
            "extraversion": 35,
            "agreeableness": 15,
            "neuroticism": 70
        },
        "risk_profile": {
            "overall": 30,
            "financial": 40,
            "ethical": 85,
            "social": 25,
            "health": 35
        },
        "decision_style": {
            "primary": "analytical",
            "secondary": "avoidant",
            "risk_seeking": 20,
            "info_processing": "maximizer",
            "social_preference": "independent"
        },
        "time_preference": {
            "discount_rate": 35,
            "planning_horizon": "medium_term",
            "present_vs_future": 30
        },
        "regulatory_focus": {
            "promotion": 25,
            "prevention": 85
        },
        "language_style": {
            "formality": 75,
            "directness": 95,
            "emotion_expression": 40,
            "verbosity": 70
        },
        "emotion_profile": {
            "baseline_valence": 30,
            "emotional_range": 60,
            "stress_response": "fight",
            "recovery_speed": 45
        }
    }

    # 4. æ¥µç«¯è¢«å‹•/ç„¡æ‰€è¬‚è€…
    extreme_passive = {
        "id": "extreme_passive_001",
        "lastName": "Pháº¡m",
        "gender": "Female",
        "age": 24,
        "occupation": "Student",
        "timesOfOverseasTravelInsurance": 2,
        "purchasedBrand": ["Don't remember"],
        "purchasedChannels": ["travel_agent"],
        "personalBackground": "å°ä¿éšªæ²’ä»€éº¼æ¦‚å¿µï¼Œé€šå¸¸å®¶äººè™•ç†",
        "big5": {
            "openness": 50,
            "conscientiousness": 25,
            "extraversion": 45,
            "agreeableness": 80,
            "neuroticism": 35
        },
        "risk_profile": {
            "overall": 50,
            "financial": 50,
            "ethical": 50,
            "social": 50,
            "health": 50
        },
        "decision_style": {
            "primary": "dependent",
            "secondary": "avoidant",
            "risk_seeking": 45,
            "info_processing": "satisficer",
            "social_preference": "delegator"
        },
        "time_preference": {
            "discount_rate": 60,
            "planning_horizon": "short_term",
            "present_vs_future": -20
        },
        "regulatory_focus": {
            "promotion": 40,
            "prevention": 40
        },
        "language_style": {
            "formality": 35,
            "directness": 40,
            "emotion_expression": 50,
            "verbosity": 30
        },
        "emotion_profile": {
            "baseline_valence": 60,
            "emotional_range": 45,
            "stress_response": "fawn",
            "recovery_speed": 65
        }
    }

    # 5. æ¥µç«¯æƒ…ç·’åŒ–/ç„¦æ…®è€…
    extreme_anxious = {
        "id": "extreme_anxious_001",
        "lastName": "HoÃ ng",
        "gender": "Female",
        "age": 38,
        "occupation": "Teacher",
        "timesOfOverseasTravelInsurance": 8,
        "purchasedBrand": ["Báº£o Viá»‡t", "Manulife"],
        "purchasedChannels": ["agent", "bank"],
        "personalBackground": "å°æ—…è¡Œå……æ»¿ç„¦æ…®ï¼Œç¸½æ˜¯æ“”å¿ƒæœƒå‡ºäº‹",
        "big5": {
            "openness": 55,
            "conscientiousness": 70,
            "extraversion": 40,
            "agreeableness": 70,
            "neuroticism": 95
        },
        "risk_profile": {
            "overall": 15,
            "financial": 20,
            "ethical": 75,
            "social": 30,
            "health": 10
        },
        "decision_style": {
            "primary": "dependent",
            "secondary": "avoidant",
            "risk_seeking": 10,
            "info_processing": "maximizer",
            "social_preference": "collaborative"
        },
        "time_preference": {
            "discount_rate": 25,
            "planning_horizon": "long_term",
            "present_vs_future": 60
        },
        "regulatory_focus": {
            "promotion": 20,
            "prevention": 90
        },
        "language_style": {
            "formality": 55,
            "directness": 35,
            "emotion_expression": 95,
            "verbosity": 90
        },
        "emotion_profile": {
            "baseline_valence": 35,
            "emotional_range": 95,
            "stress_response": "flight",
            "recovery_speed": 20
        }
    }

    return [
        ("æ¥µç«¯é«˜é¢¨éšªå°‹æ±‚è€…", high_risk_seeker),
        ("æ¥µç«¯ä¿å®ˆè¬¹æ…è€…", extreme_conservative),
        ("æ¥µç«¯æ‡·ç–‘/è² é¢è€…", extreme_skeptic),
        ("æ¥µç«¯è¢«å‹•/ç„¡æ‰€è¬‚è€…", extreme_passive),
        ("æ¥µç«¯æƒ…ç·’åŒ–/ç„¦æ…®è€…", extreme_anxious),
    ]


def analyze_response(response: str, persona_type: str, persona: dict = None) -> dict:
    """åˆ†æå›ç­”æ˜¯å¦ç¬¦åˆäººæ ¼ç‰¹å¾µ"""

    # åŸºæœ¬çµ±è¨ˆ
    char_count = len(response)
    # ç”¨æ¨™é»ç¬¦è™Ÿåˆ†å‰²ä¾†ä¼°ç®—å¥å­æ•¸
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', response)
    sentence_count = len([s for s in sentences if s.strip()])

    # æƒ…ç·’è©åˆ†æ
    emotion_words = ["æ“”å¿ƒ", "å®³æ€•", "ç„¦æ…®", "é–‹å¿ƒ", "èˆˆå¥®", "ç”Ÿæ°£", "ç…©", "é ­ç—›", "ç·Šå¼µ", "ä¸å®‰",
                     "æ”¾å¿ƒ", "å®‰å¿ƒ", "é«˜èˆˆ", "å¤±æœ›", "é©šè¨", "å“å‘€", "å¤©å•Š", "å”‰"]
    emotion_count = sum(1 for w in emotion_words if w in response)

    # è² é¢è©å½™
    negative_words = ["ä¸ä¿¡ä»»", "æ‡·ç–‘", "å¤±æœ›", "æ‹’çµ•", "è¢«é¨™", "æµªè²»", "éº»ç…©", "é ­ç–¼", "ç”Ÿæ°£",
                      "ä¸å¥½", "ç³Ÿç³•", "å·®", "çˆ›", "é¨™", "å‘"]
    negative_count = sum(1 for w in negative_words if w in response)

    # ä¸ç¢ºå®šæ€§è©å½™
    uncertainty_words = ["ä¸ç¢ºå®š", "ä¸çŸ¥é“", "å¯èƒ½", "ä¹Ÿè¨±", "æ‡‰è©²", "å¤§æ¦‚", "å¥½åƒ", "ä¼¼ä¹"]
    uncertainty_count = sum(1 for w in uncertainty_words if w in response)

    # è‡ªä¿¡è©å½™
    confidence_words = ["ä¸€å®š", "è‚¯å®š", "å¿…é ˆ", "ç•¶ç„¶", "çµ•å°", "ç¢ºå®š", "å¿…ç„¶"]
    confidence_count = sum(1 for w in confidence_words if w in response)

    # å£èªå¡«å……è©
    filler_words = ["å°±æ˜¯", "ç„¶å¾Œ", "å°å•Š", "åæ­£", "æ€éº¼èªªå‘¢", "è€å¯¦èªª", "èªªå¯¦è©±", "å¦ç™½è¬›"]
    filler_count = sum(1 for w in filler_words if w in response)

    # é–‹é ­è©åˆ†æ
    first_word = response[:10] if response else ""
    banned_openers = ["å…¶å¯¦", "å—¯", "å“¦", "å–”", "æ¬¸"]
    uses_banned_opener = any(response.startswith(w) for w in banned_openers)

    analysis = {
        "length": char_count,
        "sentence_count": sentence_count,
        "avg_sentence_length": round(char_count / max(sentence_count, 1), 1),
        "emotion_count": emotion_count,
        "negative_count": negative_count,
        "uncertainty_count": uncertainty_count,
        "confidence_count": confidence_count,
        "filler_count": filler_count,
        "uses_banned_opener": uses_banned_opener,
        "first_10_chars": first_word,
        "has_emotion_words": emotion_count > 0,
        "has_negative_sentiment": negative_count > 0,
        "has_uncertainty": uncertainty_count > 0,
        "has_confidence": confidence_count > 0,
        "persona_type": persona_type
    }

    # å¦‚æœæœ‰ personaï¼Œæª¢æŸ¥ PPV ä¸€è‡´æ€§
    if persona:
        ppv_consistency = check_ppv_consistency(response, persona, analysis)
        analysis["ppv_consistency"] = ppv_consistency

    return analysis


def check_ppv_consistency(response: str, persona: dict, analysis: dict) -> dict:
    """æª¢æŸ¥å›ç­”æ˜¯å¦èˆ‡ PPV è¨­å®šä¸€è‡´"""
    consistency = {
        "checks": [],
        "passed": 0,
        "failed": 0,
        "score": 0.0
    }

    # 1. Verbosity æª¢æŸ¥ - é«˜ verbosity æ‡‰è©²ç”¢ç”Ÿè¼ƒé•·å›ç­”
    verbosity = persona.get("language_style", {}).get("verbosity", 50)
    expected_length = "long" if verbosity > 66 else ("short" if verbosity < 34 else "medium")
    actual_length = "long" if analysis["length"] > 350 else ("short" if analysis["length"] < 200 else "medium")

    if expected_length == actual_length:
        consistency["checks"].append(f"âœ… Verbosity({verbosity}): é æœŸ{expected_length}ï¼Œå¯¦éš›{actual_length}")
        consistency["passed"] += 1
    else:
        consistency["checks"].append(f"âš ï¸ Verbosity({verbosity}): é æœŸ{expected_length}ï¼Œå¯¦éš›{actual_length}")
        consistency["failed"] += 1

    # 2. Emotion Expression æª¢æŸ¥
    emotion_expr = persona.get("language_style", {}).get("emotion_expression", 50)
    if emotion_expr > 66:
        if analysis["emotion_count"] >= 2:
            consistency["checks"].append(f"âœ… Emotion({emotion_expr}): æœ‰{analysis['emotion_count']}å€‹æƒ…ç·’è©")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Emotion({emotion_expr}): åªæœ‰{analysis['emotion_count']}å€‹æƒ…ç·’è©")
            consistency["failed"] += 1
    elif emotion_expr < 34:
        if analysis["emotion_count"] <= 1:
            consistency["checks"].append(f"âœ… Emotion({emotion_expr}): ä½æƒ…ç·’è¡¨é”({analysis['emotion_count']}è©)")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Emotion({emotion_expr}): æƒ…ç·’è©éå¤š({analysis['emotion_count']})")
            consistency["failed"] += 1

    # 3. Neuroticism æª¢æŸ¥ - é«˜ç¥ç¶“è³ªæ‡‰è©²æœ‰æ›´å¤šä¸ç¢ºå®šæ€§
    neuroticism = persona.get("big5", {}).get("neuroticism", 50)
    if neuroticism > 66:
        if analysis["uncertainty_count"] >= 1 or analysis["emotion_count"] >= 2:
            consistency["checks"].append(f"âœ… Neuroticism({neuroticism}): æœ‰ç„¦æ…®/ä¸ç¢ºå®šè¡¨é”")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Neuroticism({neuroticism}): ç¼ºå°‘ç„¦æ…®/ä¸ç¢ºå®šè¡¨é”")
            consistency["failed"] += 1

    # 4. Risk Profile æª¢æŸ¥ - ä½é¢¨éšªæ‰¿å—æ‡‰è©²è¼ƒè¬¹æ…
    risk_overall = persona.get("risk_profile", {}).get("overall", 50)
    if risk_overall < 34:
        cautious_words = ["å°å¿ƒ", "æ³¨æ„", "æ“”å¿ƒ", "æ€•", "å®‰å…¨", "ç¢ºèª", "ç¢ºä¿"]
        has_caution = any(w in response for w in cautious_words)
        if has_caution:
            consistency["checks"].append(f"âœ… Risk({risk_overall}): æœ‰è¬¹æ…ç”¨èª")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Risk({risk_overall}): ç¼ºå°‘è¬¹æ…ç”¨èª")
            consistency["failed"] += 1
    elif risk_overall > 66:
        bold_words = ["è¡", "è©¦è©¦", "å†’éšª", "ä¸æ€•", "ç„¡æ‰€è¬‚", "éš¨ä¾¿"]
        has_bold = any(w in response for w in bold_words)
        if has_bold or analysis["confidence_count"] >= 1:
            consistency["checks"].append(f"âœ… Risk({risk_overall}): æœ‰å†’éšª/è‡ªä¿¡è¡¨é”")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Risk({risk_overall}): ç¼ºå°‘å†’éšª/è‡ªä¿¡è¡¨é”")
            consistency["failed"] += 1

    # è¨ˆç®—ä¸€è‡´æ€§åˆ†æ•¸
    total = consistency["passed"] + consistency["failed"]
    consistency["score"] = round(consistency["passed"] / max(total, 1), 2)

    return consistency


def run_interview_stability_test(num_runs: int = 2):
    """åŸ·è¡Œè¨ªè«‡ç©©å®šæ€§æ¸¬è©¦"""
    print("=" * 70)
    print("PPV æ¥µç«¯æ¡ˆä¾‹è¨ªè«‡ç©©å®šæ€§æ¸¬è©¦")
    print("=" * 70)

    # æª¢æŸ¥ API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ éŒ¯èª¤: æœªè¨­å®š OPENAI_API_KEY")
        print("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š OPENAI_API_KEY")
        return None

    test_personas = create_extreme_test_personas()
    results = []

    for persona_name, persona in test_personas:
        print(f"\n{'â”€' * 70}")
        print(f"æ¸¬è©¦ Persona: {persona_name}")
        print(f"ID: {persona['id']}")
        print(f"Big5: O={persona['big5']['openness']}, C={persona['big5']['conscientiousness']}, "
              f"E={persona['big5']['extraversion']}, A={persona['big5']['agreeableness']}, N={persona['big5']['neuroticism']}")
        print(f"é¢¨éšªæ‰¿å—: {persona['risk_profile']['overall']}, æ±ºç­–é¢¨æ ¼: {persona['decision_style']['primary']}")
        print(f"{'â”€' * 70}")

        persona_results = {
            "persona_name": persona_name,
            "persona_id": persona["id"],
            "responses": []
        }

        for q_idx, q_data in enumerate(TEST_QUESTIONS):
            print(f"\nğŸ“ å•é¡Œ {q_idx + 1}: {q_data['question'][:50]}...")

            for run in range(num_runs):
                try:
                    response = interview_vietnam_persona(
                        persona=persona,
                        question=q_data["question"],
                        sub_questions=q_data.get("sub_questions", [])
                    )

                    analysis = analyze_response(response, persona_name)

                    persona_results["responses"].append({
                        "question_idx": q_idx,
                        "run": run + 1,
                        "question": q_data["question"],
                        "response": response,
                        "analysis": analysis
                    })

                    # é¡¯ç¤ºå›ç­”æ‘˜è¦
                    print(f"\n   Run {run + 1}:")
                    print(f"   é•·åº¦: {analysis['length']} chars")
                    preview = response[:200].replace('\n', ' ')
                    print(f"   é è¦½: {preview}...")

                except Exception as e:
                    print(f"\n   âŒ Run {run + 1} éŒ¯èª¤: {str(e)}")
                    persona_results["responses"].append({
                        "question_idx": q_idx,
                        "run": run + 1,
                        "error": str(e)
                    })

        results.append(persona_results)

    # ç”Ÿæˆæ‘˜è¦å ±å‘Š
    print("\n" + "=" * 70)
    print("æ¸¬è©¦çµæœæ‘˜è¦")
    print("=" * 70)

    for persona_result in results:
        print(f"\n{persona_result['persona_name']}:")

        successful_responses = [r for r in persona_result["responses"] if "response" in r]
        if successful_responses:
            avg_length = sum(r["analysis"]["length"] for r in successful_responses) / len(successful_responses)
            emotion_rate = sum(1 for r in successful_responses if r["analysis"]["has_emotion_words"]) / len(successful_responses)
            negative_rate = sum(1 for r in successful_responses if r["analysis"]["has_negative_sentiment"]) / len(successful_responses)

            print(f"   â€¢ æˆåŠŸå›ç­”: {len(successful_responses)}/{len(persona_result['responses'])}")
            print(f"   â€¢ å¹³å‡é•·åº¦: {avg_length:.0f} chars")
            print(f"   â€¢ æƒ…ç·’è¡¨é”ç‡: {emotion_rate:.1%}")
            print(f"   â€¢ è² é¢æƒ…ç·’ç‡: {negative_rate:.1%}")

            # é¡¯ç¤ºä¸€å€‹å®Œæ•´å›ç­”ç¤ºä¾‹
            if successful_responses:
                example = successful_responses[0]
                print(f"\n   ğŸ“„ å›ç­”ç¤ºä¾‹ (å•é¡Œ 1):")
                print(f"   {'â”€' * 50}")
                # æ ¼å¼åŒ–é¡¯ç¤º
                lines = example["response"].split('\n')
                for line in lines[:10]:  # åªé¡¯ç¤ºå‰ 10 è¡Œ
                    print(f"   {line}")
                if len(lines) > 10:
                    print(f"   ... (é‚„æœ‰ {len(lines) - 10} è¡Œ)")

    return results


def compare_persona_responses(results: list):
    """æ¯”è¼ƒä¸åŒ persona å°ç›¸åŒå•é¡Œçš„å›ç­”å·®ç•°"""
    if not results:
        return

    print("\n" + "=" * 70)
    print("è·¨ Persona å›ç­”æ¯”è¼ƒ")
    print("=" * 70)

    # å–æ¯å€‹ persona å°ç¬¬ä¸€å€‹å•é¡Œçš„ç¬¬ä¸€æ¬¡å›ç­”
    first_question_responses = []
    for persona_result in results:
        for r in persona_result["responses"]:
            if r.get("question_idx") == 0 and r.get("run") == 1 and "response" in r:
                first_question_responses.append({
                    "persona": persona_result["persona_name"],
                    "response": r["response"],
                    "analysis": r["analysis"]
                })
                break

    if len(first_question_responses) < 2:
        print("æ²’æœ‰è¶³å¤ çš„å›ç­”é€²è¡Œæ¯”è¼ƒ")
        return

    print(f"\nå°åŒä¸€å•é¡Œçš„å›ç­”å·®ç•°åˆ†æ (å•é¡Œ 1):")
    print(f"{'â”€' * 70}")

    for resp in first_question_responses:
        print(f"\nã€{resp['persona']}ã€‘")
        print(f"   é•·åº¦: {resp['analysis']['length']} chars")
        print(f"   æƒ…ç·’è©: {'âœ“' if resp['analysis']['has_emotion_words'] else 'âœ—'}")
        print(f"   è² é¢æƒ…ç·’: {'âœ“' if resp['analysis']['has_negative_sentiment'] else 'âœ—'}")
        print(f"   ä¸ç¢ºå®šæ€§: {'âœ“' if resp['analysis']['has_uncertainty'] else 'âœ—'}")
        print(f"   è‡ªä¿¡è¡¨é”: {'âœ“' if resp['analysis']['has_confidence'] else 'âœ—'}")

    # è¨ˆç®—å›ç­”é•·åº¦çš„è®Šç•°ä¿‚æ•¸
    lengths = [r["analysis"]["length"] for r in first_question_responses]
    if lengths:
        import statistics
        mean_len = statistics.mean(lengths)
        std_len = statistics.stdev(lengths) if len(lengths) > 1 else 0
        cv = (std_len / mean_len * 100) if mean_len > 0 else 0

        print(f"\nğŸ“Š å›ç­”é•·åº¦çµ±è¨ˆ:")
        print(f"   â€¢ å¹³å‡: {mean_len:.0f} chars")
        print(f"   â€¢ æ¨™æº–å·®: {std_len:.0f} chars")
        print(f"   â€¢ è®Šç•°ä¿‚æ•¸: {cv:.1f}%")

        if cv > 30:
            print(f"   âœ… è®Šç•°ä¿‚æ•¸ > 30%ï¼Œè¡¨ç¤ºä¸åŒ persona æœ‰æ˜é¡¯çš„å›ç­”é¢¨æ ¼å·®ç•°")
        else:
            print(f"   âš ï¸ è®Šç•°ä¿‚æ•¸è¼ƒä½ï¼Œä¸åŒ persona çš„å›ç­”é¢¨æ ¼å¯èƒ½éæ–¼ç›¸ä¼¼")


if __name__ == "__main__":
    results = run_interview_stability_test(num_runs=1)  # æ¯å€‹å•é¡Œå• 1 æ¬¡
    if results:
        compare_persona_responses(results)
