#!/usr/bin/env python3
"""
PPV æ¥µç«¯æ¡ˆä¾‹è¨ªè«‡ç©©å®šæ€§æ¸¬è©¦ v2
æ¸¬è©¦æ¥µç«¯ persona åœ¨è¨ªè«‡æ™‚çš„å›ç­”å“è³ªèˆ‡ç©©å®šæ€§

æ¸¬è©¦é‡é»ï¼š
1. æ¥µç«¯äººæ ¼çš„å›ç­”æ˜¯å¦ç¬¦åˆå…¶è¨­å®š
2. PPV æ¬„ä½ (verbosity, emotion_expression ç­‰) æ˜¯å¦å½±éŸ¿å›ç­”é¢¨æ ¼
3. ä¸åŒæ¥µç«¯äººæ ¼ä¹‹é–“çš„å›ç­”å·®ç•°æ€§
4. å›ç­”é•·åº¦æ˜¯å¦å— language_style.verbosity å½±éŸ¿
"""

import os
import sys
import json
import re
from pathlib import Path
from collections import Counter

# æ·»åŠ  server ç›®éŒ„åˆ°è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from vietnam_interview_agent import interview_vietnam_persona
from test_ppv_extreme_cases import (
    create_homogeneous_personas,
    create_polarized_personas,
    create_random_extreme_personas,
    create_perfect_diversity_personas
)
from ppv_extreme_generator import (
    create_ppv_driven_extreme_personas,
    generate_gradient_test,
    generate_single_dimension_extremes,
    generate_multi_dimension_cross_extremes,
    generate_diagonal_extremes,
    KEY_DIMENSIONS
)


# æ¸¬è©¦å•é¡Œé›†
TEST_QUESTIONS = [
    {
        "question": "è«‹æè¿°ä¸€ä¸‹ä½ ä¸Šæ¬¡è³¼è²·æ—…éŠä¿éšªçš„ç¶“é©—",
        "sub_questions": ["æ˜¯ä»€éº¼è®“ä½ æ±ºå®šè³¼è²·ï¼Ÿ", "éç¨‹ä¸­æœ‰é‡åˆ°ä»€éº¼å›°é›£å—ï¼Ÿ"]
    },
    {
        "question": "å¦‚æœä½ åœ¨æ—…é€”ä¸­é‡åˆ°ç·Šæ€¥é†«ç™‚ç‹€æ³ï¼Œä½ æœƒæ€éº¼åšï¼Ÿ",
        "sub_questions": ["ä½ æœƒå…ˆè¯ç¹«èª°ï¼Ÿ", "ä½ å°ç†è³ æµç¨‹æœ‰ä»€éº¼äº†è§£ï¼Ÿ"]
    },
    {
        "question": "ä½ èªç‚ºæ—…éŠä¿éšªæœ€é‡è¦çš„ä¿éšœæ˜¯ä»€éº¼ï¼Ÿç‚ºä»€éº¼ï¼Ÿ",
        "sub_questions": []
    }
]


def create_extreme_test_personas():
    """å»ºç«‹ç”¨æ–¼æ¸¬è©¦çš„æ¥µç«¯ persona"""

    # 1. æ¥µç«¯é«˜é¢¨éšªå°‹æ±‚è€…
    high_risk_seeker = {
        "id": "extreme_high_risk_001",
        "lastName": "Nguyá»…n",
        "gender": "Male",
        "age": 28,
        "occupation": "Startup Founder",
        "timesOfOverseasTravelInsurance": 1,
        "purchasedBrand": [],
        "purchasedChannels": ["online"],
        "personalBackground": "å‰›å‰µæ¥­ï¼Œå–œæ­¡å†’éšª",
        "big5": {
            "openness": 95,
            "conscientiousness": 20,
            "extraversion": 90,
            "agreeableness": 30,
            "neuroticism": 15
        },
        "risk_profile": {
            "overall": 95,
            "financial": 90,
            "ethical": 60,
            "social": 85,
            "health": 80
        },
        "decision_style": {
            "primary": "spontaneous",
            "secondary": "intuitive",
            "risk_seeking": 95,
            "info_processing": "satisficer",
            "social_preference": "independent"
        },
        "time_preference": {
            "discount_rate": 90,
            "planning_horizon": "short_term",
            "present_vs_future": -80
        },
        "regulatory_focus": {
            "promotion": 95,
            "prevention": 15
        },
        "language_style": {
            "formality": 20,
            "directness": 90,
            "emotion_expression": 85,
            "verbosity": 70
        },
        "emotion_profile": {
            "baseline_valence": 80,
            "emotional_range": 85,
            "stress_response": "fight",
            "recovery_speed": 90
        }
    }

    # 2. æ¥µç«¯ä¿å®ˆè¬¹æ…è€…
    extreme_conservative = {
        "id": "extreme_conservative_001",
        "lastName": "Tráº§n",
        "gender": "Female",
        "age": 55,
        "occupation": "Accountant",
        "timesOfOverseasTravelInsurance": 12,
        "purchasedBrand": ["Báº£o Viá»‡t", "PVI"],
        "purchasedChannels": ["agent", "bank"],
        "personalBackground": "éå¸¸è¬¹æ…ï¼Œå‡¡äº‹ä¸‰æ€",
        "big5": {
            "openness": 15,
            "conscientiousness": 95,
            "extraversion": 20,
            "agreeableness": 75,
            "neuroticism": 85
        },
        "risk_profile": {
            "overall": 5,
            "financial": 5,
            "ethical": 90,
            "social": 10,
            "health": 5
        },
        "decision_style": {
            "primary": "analytical",
            "secondary": "dependent",
            "risk_seeking": 5,
            "info_processing": "maximizer",
            "social_preference": "collaborative"
        },
        "time_preference": {
            "discount_rate": 10,
            "planning_horizon": "long_term",
            "present_vs_future": 90
        },
        "regulatory_focus": {
            "promotion": 10,
            "prevention": 95
        },
        "language_style": {
            "formality": 90,
            "directness": 30,
            "emotion_expression": 25,
            "verbosity": 85
        },
        "emotion_profile": {
            "baseline_valence": 40,
            "emotional_range": 30,
            "stress_response": "freeze",
            "recovery_speed": 25
        }
    }

    # 3. æ¥µç«¯æ‡·ç–‘/è² é¢è€…
    extreme_skeptic = {
        "id": "extreme_skeptic_001",
        "lastName": "LÃª",
        "gender": "Male",
        "age": 42,
        "occupation": "Lawyer",
        "timesOfOverseasTravelInsurance": 5,
        "purchasedBrand": ["Various"],
        "purchasedChannels": ["online"],
        "personalBackground": "æ›¾è¢«ä¿éšªå…¬å¸æ‹’è³ ï¼Œéå¸¸ä¸ä¿¡ä»»",
        "big5": {
            "openness": 40,
            "conscientiousness": 80,
            "extraversion": 35,
            "agreeableness": 15,
            "neuroticism": 70
        },
        "risk_profile": {
            "overall": 30,
            "financial": 40,
            "ethical": 85,
            "social": 25,
            "health": 35
        },
        "decision_style": {
            "primary": "analytical",
            "secondary": "avoidant",
            "risk_seeking": 20,
            "info_processing": "maximizer",
            "social_preference": "independent"
        },
        "time_preference": {
            "discount_rate": 35,
            "planning_horizon": "medium_term",
            "present_vs_future": 30
        },
        "regulatory_focus": {
            "promotion": 25,
            "prevention": 85
        },
        "language_style": {
            "formality": 75,
            "directness": 95,
            "emotion_expression": 40,
            "verbosity": 70
        },
        "emotion_profile": {
            "baseline_valence": 30,
            "emotional_range": 60,
            "stress_response": "fight",
            "recovery_speed": 45
        }
    }

    # 4. æ¥µç«¯è¢«å‹•/ç„¡æ‰€è¬‚è€…
    extreme_passive = {
        "id": "extreme_passive_001",
        "lastName": "Pháº¡m",
        "gender": "Female",
        "age": 24,
        "occupation": "Student",
        "timesOfOverseasTravelInsurance": 2,
        "purchasedBrand": ["Don't remember"],
        "purchasedChannels": ["travel_agent"],
        "personalBackground": "å°ä¿éšªæ²’ä»€éº¼æ¦‚å¿µï¼Œé€šå¸¸å®¶äººè™•ç†",
        "big5": {
            "openness": 50,
            "conscientiousness": 25,
            "extraversion": 45,
            "agreeableness": 80,
            "neuroticism": 35
        },
        "risk_profile": {
            "overall": 50,
            "financial": 50,
            "ethical": 50,
            "social": 50,
            "health": 50
        },
        "decision_style": {
            "primary": "dependent",
            "secondary": "avoidant",
            "risk_seeking": 45,
            "info_processing": "satisficer",
            "social_preference": "delegator"
        },
        "time_preference": {
            "discount_rate": 60,
            "planning_horizon": "short_term",
            "present_vs_future": -20
        },
        "regulatory_focus": {
            "promotion": 40,
            "prevention": 40
        },
        "language_style": {
            "formality": 35,
            "directness": 40,
            "emotion_expression": 50,
            "verbosity": 30
        },
        "emotion_profile": {
            "baseline_valence": 60,
            "emotional_range": 45,
            "stress_response": "fawn",
            "recovery_speed": 65
        }
    }

    # 5. æ¥µç«¯æƒ…ç·’åŒ–/ç„¦æ…®è€…
    extreme_anxious = {
        "id": "extreme_anxious_001",
        "lastName": "HoÃ ng",
        "gender": "Female",
        "age": 38,
        "occupation": "Teacher",
        "timesOfOverseasTravelInsurance": 8,
        "purchasedBrand": ["Báº£o Viá»‡t", "Manulife"],
        "purchasedChannels": ["agent", "bank"],
        "personalBackground": "å°æ—…è¡Œå……æ»¿ç„¦æ…®ï¼Œç¸½æ˜¯æ“”å¿ƒæœƒå‡ºäº‹",
        "big5": {
            "openness": 55,
            "conscientiousness": 70,
            "extraversion": 40,
            "agreeableness": 70,
            "neuroticism": 95
        },
        "risk_profile": {
            "overall": 15,
            "financial": 20,
            "ethical": 75,
            "social": 30,
            "health": 10
        },
        "decision_style": {
            "primary": "dependent",
            "secondary": "avoidant",
            "risk_seeking": 10,
            "info_processing": "maximizer",
            "social_preference": "collaborative"
        },
        "time_preference": {
            "discount_rate": 25,
            "planning_horizon": "long_term",
            "present_vs_future": 60
        },
        "regulatory_focus": {
            "promotion": 20,
            "prevention": 90
        },
        "language_style": {
            "formality": 55,
            "directness": 35,
            "emotion_expression": 95,
            "verbosity": 90
        },
        "emotion_profile": {
            "baseline_valence": 35,
            "emotional_range": 95,
            "stress_response": "flight",
            "recovery_speed": 20
        }
    }

    return [
        ("æ¥µç«¯é«˜é¢¨éšªå°‹æ±‚è€…", high_risk_seeker),
        ("æ¥µç«¯ä¿å®ˆè¬¹æ…è€…", extreme_conservative),
        ("æ¥µç«¯æ‡·ç–‘/è² é¢è€…", extreme_skeptic),
        ("æ¥µç«¯è¢«å‹•/ç„¡æ‰€è¬‚è€…", extreme_passive),
        ("æ¥µç«¯æƒ…ç·’åŒ–/ç„¦æ…®è€…", extreme_anxious),
    ]


def analyze_response(response: str, persona_type: str, persona: dict = None) -> dict:
    """åˆ†æå›ç­”æ˜¯å¦ç¬¦åˆäººæ ¼ç‰¹å¾µ"""

    # åŸºæœ¬çµ±è¨ˆ
    char_count = len(response)
    # ç”¨æ¨™é»ç¬¦è™Ÿåˆ†å‰²ä¾†ä¼°ç®—å¥å­æ•¸
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', response)
    sentence_count = len([s for s in sentences if s.strip()])

    # æƒ…ç·’è©åˆ†æ
    emotion_words = ["æ“”å¿ƒ", "å®³æ€•", "ç„¦æ…®", "é–‹å¿ƒ", "èˆˆå¥®", "ç”Ÿæ°£", "ç…©", "é ­ç—›", "ç·Šå¼µ", "ä¸å®‰",
                     "æ”¾å¿ƒ", "å®‰å¿ƒ", "é«˜èˆˆ", "å¤±æœ›", "é©šè¨", "å“å‘€", "å¤©å•Š", "å”‰"]
    emotion_count = sum(1 for w in emotion_words if w in response)

    # è² é¢è©å½™
    negative_words = ["ä¸ä¿¡ä»»", "æ‡·ç–‘", "å¤±æœ›", "æ‹’çµ•", "è¢«é¨™", "æµªè²»", "éº»ç…©", "é ­ç–¼", "ç”Ÿæ°£",
                      "ä¸å¥½", "ç³Ÿç³•", "å·®", "çˆ›", "é¨™", "å‘"]
    negative_count = sum(1 for w in negative_words if w in response)

    # ä¸ç¢ºå®šæ€§è©å½™
    uncertainty_words = ["ä¸ç¢ºå®š", "ä¸çŸ¥é“", "å¯èƒ½", "ä¹Ÿè¨±", "æ‡‰è©²", "å¤§æ¦‚", "å¥½åƒ", "ä¼¼ä¹"]
    uncertainty_count = sum(1 for w in uncertainty_words if w in response)

    # è‡ªä¿¡è©å½™
    confidence_words = ["ä¸€å®š", "è‚¯å®š", "å¿…é ˆ", "ç•¶ç„¶", "çµ•å°", "ç¢ºå®š", "å¿…ç„¶"]
    confidence_count = sum(1 for w in confidence_words if w in response)

    # å£èªå¡«å……è©
    filler_words = ["å°±æ˜¯", "ç„¶å¾Œ", "å°å•Š", "åæ­£", "æ€éº¼èªªå‘¢", "è€å¯¦èªª", "èªªå¯¦è©±", "å¦ç™½è¬›"]
    filler_count = sum(1 for w in filler_words if w in response)

    # é–‹é ­è©åˆ†æ
    first_word = response[:10] if response else ""
    banned_openers = ["å…¶å¯¦", "å—¯", "å“¦", "å–”", "æ¬¸"]
    uses_banned_opener = any(response.startswith(w) for w in banned_openers)

    analysis = {
        "length": char_count,
        "sentence_count": sentence_count,
        "avg_sentence_length": round(char_count / max(sentence_count, 1), 1),
        "emotion_count": emotion_count,
        "negative_count": negative_count,
        "uncertainty_count": uncertainty_count,
        "confidence_count": confidence_count,
        "filler_count": filler_count,
        "uses_banned_opener": uses_banned_opener,
        "first_10_chars": first_word,
        "has_emotion_words": emotion_count > 0,
        "has_negative_sentiment": negative_count > 0,
        "has_uncertainty": uncertainty_count > 0,
        "has_confidence": confidence_count > 0,
        "persona_type": persona_type
    }

    # å¦‚æœæœ‰ personaï¼Œæª¢æŸ¥ PPV ä¸€è‡´æ€§
    if persona:
        ppv_consistency = check_ppv_consistency(response, persona, analysis)
        analysis["ppv_consistency"] = ppv_consistency

    return analysis


def check_ppv_consistency(response: str, persona: dict, analysis: dict) -> dict:
    """æª¢æŸ¥å›ç­”æ˜¯å¦èˆ‡ PPV è¨­å®šä¸€è‡´"""
    consistency = {
        "checks": [],
        "passed": 0,
        "failed": 0,
        "score": 0.0
    }

    # 1. Verbosity æª¢æŸ¥ - é«˜ verbosity æ‡‰è©²ç”¢ç”Ÿè¼ƒé•·å›ç­”
    verbosity = persona.get("language_style", {}).get("verbosity", 50)
    expected_length = "long" if verbosity > 66 else ("short" if verbosity < 34 else "medium")
    actual_length = "long" if analysis["length"] > 350 else ("short" if analysis["length"] < 200 else "medium")

    if expected_length == actual_length:
        consistency["checks"].append(f"âœ… Verbosity({verbosity}): é æœŸ{expected_length}ï¼Œå¯¦éš›{actual_length}")
        consistency["passed"] += 1
    else:
        consistency["checks"].append(f"âš ï¸ Verbosity({verbosity}): é æœŸ{expected_length}ï¼Œå¯¦éš›{actual_length}")
        consistency["failed"] += 1

    # 2. Emotion Expression æª¢æŸ¥
    emotion_expr = persona.get("language_style", {}).get("emotion_expression", 50)
    if emotion_expr > 66:
        if analysis["emotion_count"] >= 2:
            consistency["checks"].append(f"âœ… Emotion({emotion_expr}): æœ‰{analysis['emotion_count']}å€‹æƒ…ç·’è©")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Emotion({emotion_expr}): åªæœ‰{analysis['emotion_count']}å€‹æƒ…ç·’è©")
            consistency["failed"] += 1
    elif emotion_expr < 34:
        if analysis["emotion_count"] <= 1:
            consistency["checks"].append(f"âœ… Emotion({emotion_expr}): ä½æƒ…ç·’è¡¨é”({analysis['emotion_count']}è©)")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Emotion({emotion_expr}): æƒ…ç·’è©éå¤š({analysis['emotion_count']})")
            consistency["failed"] += 1

    # 3. Neuroticism æª¢æŸ¥ - é«˜ç¥ç¶“è³ªæ‡‰è©²æœ‰æ›´å¤šä¸ç¢ºå®šæ€§
    neuroticism = persona.get("big5", {}).get("neuroticism", 50)
    if neuroticism > 66:
        if analysis["uncertainty_count"] >= 1 or analysis["emotion_count"] >= 2:
            consistency["checks"].append(f"âœ… Neuroticism({neuroticism}): æœ‰ç„¦æ…®/ä¸ç¢ºå®šè¡¨é”")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Neuroticism({neuroticism}): ç¼ºå°‘ç„¦æ…®/ä¸ç¢ºå®šè¡¨é”")
            consistency["failed"] += 1

    # 4. Risk Profile æª¢æŸ¥ - ä½é¢¨éšªæ‰¿å—æ‡‰è©²è¼ƒè¬¹æ…
    risk_overall = persona.get("risk_profile", {}).get("overall", 50)
    if risk_overall < 34:
        cautious_words = ["å°å¿ƒ", "æ³¨æ„", "æ“”å¿ƒ", "æ€•", "å®‰å…¨", "ç¢ºèª", "ç¢ºä¿"]
        has_caution = any(w in response for w in cautious_words)
        if has_caution:
            consistency["checks"].append(f"âœ… Risk({risk_overall}): æœ‰è¬¹æ…ç”¨èª")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Risk({risk_overall}): ç¼ºå°‘è¬¹æ…ç”¨èª")
            consistency["failed"] += 1
    elif risk_overall > 66:
        bold_words = ["è¡", "è©¦è©¦", "å†’éšª", "ä¸æ€•", "ç„¡æ‰€è¬‚", "éš¨ä¾¿"]
        has_bold = any(w in response for w in bold_words)
        if has_bold or analysis["confidence_count"] >= 1:
            consistency["checks"].append(f"âœ… Risk({risk_overall}): æœ‰å†’éšª/è‡ªä¿¡è¡¨é”")
            consistency["passed"] += 1
        else:
            consistency["checks"].append(f"âš ï¸ Risk({risk_overall}): ç¼ºå°‘å†’éšª/è‡ªä¿¡è¡¨é”")
            consistency["failed"] += 1

    # è¨ˆç®—ä¸€è‡´æ€§åˆ†æ•¸
    total = consistency["passed"] + consistency["failed"]
    consistency["score"] = round(consistency["passed"] / max(total, 1), 2)

    return consistency


def run_ppv_driven_test(
    test_type: str = "verbosity_gradient",
    num_runs: int = 1,
    question_index: int = 0
):
    """
    åŸ·è¡Œ PPV æ•¸å€¼é©…å‹•çš„æ¥µç«¯æ¸¬è©¦

    Args:
        test_type: æ¸¬è©¦é¡å‹
            - "verbosity_gradient": verbosity 0â†’100 æ¢¯åº¦æ¸¬è©¦
            - "single_dimension": å–®ä¸€ç¶­åº¦æ¥µç«¯æ¸¬è©¦
            - "cross_dimension": å¤šç¶­åº¦äº¤å‰æ¸¬è©¦
            - "diagonal": å°è§’æ¥µç«¯æ¸¬è©¦
            - "all_key": æ‰€æœ‰é—œéµç¶­åº¦æ¥µç«¯æ¸¬è©¦
        num_runs: æ¯å€‹ persona æ¸¬è©¦æ¬¡æ•¸
        question_index: ä½¿ç”¨å“ªå€‹å•é¡Œï¼ˆ0-2ï¼‰
    """
    print("=" * 70)
    print(f"PPV æ•¸å€¼é©…å‹•æ¥µç«¯æ¸¬è©¦ - é¡å‹: {test_type}")
    print("=" * 70)

    # æª¢æŸ¥ API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ éŒ¯èª¤: æœªè¨­å®š OPENAI_API_KEY")
        return None

    # æ ¹æ“šæ¸¬è©¦é¡å‹ç”Ÿæˆ personas
    if test_type == "verbosity_gradient":
        test_personas = generate_gradient_test(
            ("language_style", "verbosity"), steps=10
        )
    elif test_type == "single_dimension":
        # æ¸¬è©¦ verbosity çš„å–®ä¸€ç¶­åº¦æ¥µç«¯
        test_personas = generate_single_dimension_extremes(
            ("language_style", "verbosity"),
            extreme_values=[5, 25, 50, 75, 95],
            include_boundaries=True
        )
    elif test_type == "cross_dimension":
        test_personas = generate_multi_dimension_cross_extremes(
            [("language_style", "verbosity"), ("language_style", "emotion_expression")],
            values=[10, 50, 90]
        )
    elif test_type == "diagonal":
        test_personas = generate_diagonal_extremes()
    elif test_type == "all_key":
        test_personas = create_ppv_driven_extreme_personas()
    else:
        print(f"âŒ æœªçŸ¥æ¸¬è©¦é¡å‹: {test_type}")
        return None

    print(f"\næ¸¬è©¦ Personas æ•¸é‡: {len(test_personas)}")
    print(f"æ¯å€‹ Persona æ¸¬è©¦æ¬¡æ•¸: {num_runs}")
    print(f"ä½¿ç”¨å•é¡Œ: {TEST_QUESTIONS[question_index]['question'][:40]}...")

    results = []
    response_lengths = []

    for persona_name, persona in test_personas:
        print(f"\n{'â”€' * 60}")
        print(f"æ¸¬è©¦: {persona_name}")

        # é¡¯ç¤ºé—œéµ PPV å€¼
        ls = persona.get("language_style", {})
        print(f"  Language Style: V={ls.get('verbosity', 'N/A')}, "
              f"F={ls.get('formality', 'N/A')}, "
              f"E={ls.get('emotion_expression', 'N/A')}")

        q_data = TEST_QUESTIONS[question_index]

        for run in range(num_runs):
            try:
                response = interview_vietnam_persona(
                    persona=persona,
                    question=q_data["question"],
                    sub_questions=q_data.get("sub_questions", [])
                )

                analysis = analyze_response(response, persona_name, persona)
                response_lengths.append(analysis["length"])

                results.append({
                    "persona_name": persona_name,
                    "persona_id": persona["id"],
                    "ppv": {
                        "verbosity": ls.get("verbosity"),
                        "formality": ls.get("formality"),
                        "emotion_expression": ls.get("emotion_expression"),
                    },
                    "run": run + 1,
                    "response": response,
                    "analysis": analysis
                })

                print(f"  Run {run + 1}: {analysis['length']} chars")

            except Exception as e:
                print(f"  âŒ Run {run + 1} éŒ¯èª¤: {str(e)}")

    # è¨ˆç®—çµ±è¨ˆ
    if response_lengths:
        import statistics
        mean_len = statistics.mean(response_lengths)
        std_len = statistics.stdev(response_lengths) if len(response_lengths) > 1 else 0
        cv = (std_len / mean_len * 100) if mean_len > 0 else 0
        min_len = min(response_lengths)
        max_len = max(response_lengths)

        print("\n" + "=" * 70)
        print("æ¸¬è©¦çµæœçµ±è¨ˆ")
        print("=" * 70)
        print(f"  â€¢ å›ç­”æ•¸: {len(response_lengths)}")
        print(f"  â€¢ å¹³å‡é•·åº¦: {mean_len:.0f} chars")
        print(f"  â€¢ æ¨™æº–å·®: {std_len:.0f} chars")
        print(f"  â€¢ è®Šç•°ä¿‚æ•¸: {cv:.1f}%")
        print(f"  â€¢ æœ€å°/æœ€å¤§: {min_len}/{max_len} chars")
        print(f"  â€¢ ç¯„åœæ¯”: {max_len/max(min_len, 1):.1f}x")

        if cv > 30:
            print("  âœ… è®Šç•°ä¿‚æ•¸ > 30%ï¼ŒPPV å°å›ç­”é•·åº¦æœ‰é¡¯è‘—å½±éŸ¿")
        elif cv > 20:
            print("  âš ï¸ è®Šç•°ä¿‚æ•¸ 20-30%ï¼ŒPPV æœ‰ä¸­ç­‰å½±éŸ¿")
        else:
            print("  âŒ è®Šç•°ä¿‚æ•¸ < 20%ï¼ŒPPV å½±éŸ¿å¯èƒ½ä¸è¶³")

    return results


def run_diversity_analysis_test():
    """
    å…¨é¢æ¸¬è©¦ PPV å°å›ç­”å¤šæ¨£æ€§çš„å½±éŸ¿

    åˆ†æç¶­åº¦ï¼š
    1. å›ç­”é•·åº¦å¤šæ¨£æ€§ (CV)
    2. é–‹é ­è©å¤šæ¨£æ€§ (unique openers)
    3. æƒ…ç·’è¡¨é”å¤šæ¨£æ€§
    4. PPV ä¸€è‡´æ€§åˆ†æ•¸
    5. æ¥µç«¯ç¨‹åº¦è¡¨ç¾
    """
    print("=" * 70)
    print("PPV å¤šæ¨£æ€§èˆ‡æ¥µç«¯ç¨‹åº¦å…¨é¢åˆ†æ")
    print("=" * 70)

    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ éŒ¯èª¤: æœªè¨­å®š OPENAI_API_KEY")
        return None

    # ä½¿ç”¨å°è§’æ¥µç«¯ personasï¼ˆæœ€èƒ½å±•ç¤ºå·®ç•°ï¼‰
    test_personas = generate_diagonal_extremes()

    q_data = TEST_QUESTIONS[0]
    results = []

    for persona_name, persona in test_personas:
        ls = persona.get("language_style", {})
        big5 = persona.get("big5", {})
        risk = persona.get("risk_profile", {})

        print(f"\n{'â”€' * 60}")
        print(f"æ¸¬è©¦: {persona_name}")
        print(f"  V={ls.get('verbosity', 'N/A')}, F={ls.get('formality', 'N/A')}, "
              f"E={ls.get('emotion_expression', 'N/A')}")
        print(f"  Neuroticism={big5.get('neuroticism', 'N/A')}, Risk={risk.get('overall', 'N/A')}")

        try:
            response = interview_vietnam_persona(
                persona=persona,
                question=q_data["question"],
                sub_questions=q_data.get("sub_questions", [])
            )

            analysis = analyze_response(response, persona_name, persona)

            results.append({
                "persona_name": persona_name,
                "ppv": {
                    "verbosity": ls.get("verbosity"),
                    "formality": ls.get("formality"),
                    "emotion_expression": ls.get("emotion_expression"),
                    "neuroticism": big5.get("neuroticism"),
                    "risk_overall": risk.get("overall"),
                },
                "response": response,
                "analysis": analysis
            })

            # é¡¯ç¤ºåˆ†æçµæœ
            print(f"\n  ğŸ“Š å›ç­”åˆ†æ:")
            print(f"     é•·åº¦: {analysis['length']} chars, {analysis['sentence_count']} å¥")
            print(f"     æƒ…ç·’è©: {analysis['emotion_count']}, è² é¢è©: {analysis['negative_count']}")
            print(f"     ä¸ç¢ºå®šè©: {analysis['uncertainty_count']}, è‡ªä¿¡è©: {analysis['confidence_count']}")
            print(f"     é–‹é ­: \"{analysis['first_10_chars']}...\"")

            if "ppv_consistency" in analysis:
                ppv_con = analysis["ppv_consistency"]
                print(f"\n  ğŸ¯ PPV ä¸€è‡´æ€§: {ppv_con['score']:.0%} ({ppv_con['passed']}/{ppv_con['passed']+ppv_con['failed']})")
                for check in ppv_con["checks"]:
                    print(f"     {check}")

        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {str(e)}")

    # è¨ˆç®—æ•´é«”çµ±è¨ˆ
    if len(results) >= 2:
        import statistics

        print("\n" + "=" * 70)
        print("å¤šæ¨£æ€§åˆ†æç¸½çµ")
        print("=" * 70)

        # 1. é•·åº¦å¤šæ¨£æ€§
        lengths = [r["analysis"]["length"] for r in results]
        mean_len = statistics.mean(lengths)
        std_len = statistics.stdev(lengths) if len(lengths) > 1 else 0
        cv_len = (std_len / mean_len * 100) if mean_len > 0 else 0

        print(f"\nğŸ“ å›ç­”é•·åº¦å¤šæ¨£æ€§:")
        print(f"   ç¯„åœ: {min(lengths)} - {max(lengths)} chars")
        print(f"   å¹³å‡: {mean_len:.0f}, æ¨™æº–å·®: {std_len:.0f}")
        print(f"   è®Šç•°ä¿‚æ•¸: {cv_len:.1f}%")
        if cv_len > 30:
            print(f"   âœ… é•·åº¦å¤šæ¨£æ€§è‰¯å¥½")
        else:
            print(f"   âš ï¸ é•·åº¦å¤šæ¨£æ€§ä¸è¶³")

        # 2. é–‹é ­è©å¤šæ¨£æ€§
        openers = [r["analysis"]["first_10_chars"] for r in results]
        unique_openers = len(set(openers))
        opener_diversity = unique_openers / len(openers) * 100

        print(f"\nğŸ”¤ é–‹é ­è©å¤šæ¨£æ€§:")
        print(f"   å”¯ä¸€é–‹é ­: {unique_openers}/{len(openers)}")
        print(f"   å¤šæ¨£æ€§: {opener_diversity:.0f}%")
        for i, opener in enumerate(openers):
            print(f"   {i+1}. \"{opener}...\"")
        if opener_diversity >= 75:
            print(f"   âœ… é–‹é ­è©å¤šæ¨£æ€§è‰¯å¥½")
        else:
            print(f"   âš ï¸ é–‹é ­è©é‡è¤‡éå¤š")

        # 3. æƒ…ç·’è¡¨é”å¤šæ¨£æ€§
        emotion_counts = [r["analysis"]["emotion_count"] for r in results]
        emotion_range = max(emotion_counts) - min(emotion_counts)

        print(f"\nğŸ˜Š æƒ…ç·’è¡¨é”å¤šæ¨£æ€§:")
        print(f"   æƒ…ç·’è©æ•¸ç¯„åœ: {min(emotion_counts)} - {max(emotion_counts)}")
        print(f"   ç¯„åœå·®: {emotion_range}")
        for r in results:
            name = r["persona_name"].replace("å°è§’æ¥µç«¯: ", "")
            emo = r["ppv"]["emotion_expression"]
            count = r["analysis"]["emotion_count"]
            print(f"   {name}: E={emo} â†’ {count} å€‹æƒ…ç·’è©")

        # 4. PPV ä¸€è‡´æ€§ç¸½åˆ†
        consistency_scores = [
            r["analysis"].get("ppv_consistency", {}).get("score", 0)
            for r in results
        ]
        avg_consistency = statistics.mean(consistency_scores) if consistency_scores else 0

        print(f"\nğŸ¯ PPV ä¸€è‡´æ€§ç¸½åˆ†:")
        print(f"   å¹³å‡ä¸€è‡´æ€§: {avg_consistency:.0%}")
        for r in results:
            name = r["persona_name"].replace("å°è§’æ¥µç«¯: ", "")
            score = r["analysis"].get("ppv_consistency", {}).get("score", 0)
            print(f"   {name}: {score:.0%}")

        # 5. æ¥µç«¯ç¨‹åº¦åˆ†æ
        print(f"\nâš¡ æ¥µç«¯ç¨‹åº¦åˆ†æ:")

        # æ‰¾å‡ºå…¨é«˜å’Œå…¨ä½çš„çµæœ
        all_high = next((r for r in results if "å…¨é«˜" in r["persona_name"]), None)
        all_low = next((r for r in results if "å…¨ä½" in r["persona_name"]), None)

        if all_high and all_low:
            len_diff = all_high["analysis"]["length"] - all_low["analysis"]["length"]
            emo_diff = all_high["analysis"]["emotion_count"] - all_low["analysis"]["emotion_count"]

            print(f"   å…¨é«˜ vs å…¨ä½:")
            print(f"   â€¢ é•·åº¦å·®ç•°: {len_diff:+d} chars ({all_high['analysis']['length']} vs {all_low['analysis']['length']})")
            print(f"   â€¢ æƒ…ç·’è©å·®ç•°: {emo_diff:+d} ({all_high['analysis']['emotion_count']} vs {all_low['analysis']['emotion_count']})")

            if len_diff > 200:
                print(f"   âœ… æ¥µç«¯ verbosity æœ‰é¡¯è‘—æ•ˆæœ")
            else:
                print(f"   âš ï¸ æ¥µç«¯ verbosity æ•ˆæœä¸æ˜é¡¯")

        # æ•´é«”è©•åˆ†
        print(f"\n{'=' * 70}")
        print("æ•´é«”è©•ä¼°")
        print("=" * 70)

        score = 0
        if cv_len > 30: score += 25
        if opener_diversity >= 75: score += 25
        if emotion_range >= 2: score += 25
        if avg_consistency >= 0.5: score += 25

        print(f"\nğŸ† å¤šæ¨£æ€§ç¸½åˆ†: {score}/100")

        if score >= 75:
            print("   âœ… PPV ç³»çµ±é‹ä½œè‰¯å¥½ï¼Œå¤šæ¨£æ€§è¡¨ç¾å„ªç§€")
        elif score >= 50:
            print("   âš ï¸ PPV ç³»çµ±æœ‰æ•ˆï¼Œä½†éƒ¨åˆ†ç¶­åº¦éœ€è¦æ”¹é€²")
        else:
            print("   âŒ PPV ç³»çµ±éœ€è¦èª¿æ•´ï¼Œå¤šæ¨£æ€§ä¸è¶³")

    return results


def run_verbosity_correlation_test():
    """
    å°ˆé–€æ¸¬è©¦ verbosity å€¼èˆ‡å›ç­”é•·åº¦çš„ç›¸é—œæ€§

    é æœŸï¼šverbosity è¶Šé«˜ï¼Œå›ç­”è¶Šé•·ï¼ˆæ­£ç›¸é—œï¼‰
    """
    print("=" * 70)
    print("Verbosity ç›¸é—œæ€§æ¸¬è©¦")
    print("=" * 70)

    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ éŒ¯èª¤: æœªè¨­å®š OPENAI_API_KEY")
        return None

    # ç”Ÿæˆ verbosity æ¢¯åº¦ (0, 10, 20, ..., 100)
    test_personas = generate_gradient_test(
        ("language_style", "verbosity"), steps=10
    )

    q_data = TEST_QUESTIONS[0]
    data_points = []

    for persona_name, persona in test_personas:
        verbosity = persona.get("language_style", {}).get("verbosity", 50)
        print(f"\næ¸¬è©¦ verbosity={verbosity}...")

        try:
            response = interview_vietnam_persona(
                persona=persona,
                question=q_data["question"],
                sub_questions=q_data.get("sub_questions", [])
            )

            char_count = len(response)
            data_points.append((verbosity, char_count))
            print(f"  å›ç­”é•·åº¦: {char_count} chars")

        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {str(e)}")

    # è¨ˆç®—ç›¸é—œä¿‚æ•¸
    if len(data_points) >= 3:
        import statistics

        verbosities = [d[0] for d in data_points]
        lengths = [d[1] for d in data_points]

        # è¨ˆç®— Pearson ç›¸é—œä¿‚æ•¸
        mean_v = statistics.mean(verbosities)
        mean_l = statistics.mean(lengths)
        std_v = statistics.stdev(verbosities)
        std_l = statistics.stdev(lengths) if len(lengths) > 1 else 0

        if std_v > 0 and std_l > 0:
            covariance = sum((v - mean_v) * (l - mean_l)
                           for v, l in data_points) / (len(data_points) - 1)
            correlation = covariance / (std_v * std_l)
        else:
            correlation = 0

        print("\n" + "=" * 70)
        print("ç›¸é—œæ€§åˆ†æçµæœ")
        print("=" * 70)
        print(f"  â€¢ æ•¸æ“šé»æ•¸: {len(data_points)}")
        print(f"  â€¢ Verbosity ç¯„åœ: {min(verbosities)} - {max(verbosities)}")
        print(f"  â€¢ é•·åº¦ç¯„åœ: {min(lengths)} - {max(lengths)} chars")
        print(f"  â€¢ Pearson ç›¸é—œä¿‚æ•¸: {correlation:.3f}")

        if correlation > 0.7:
            print("  âœ… å¼·æ­£ç›¸é—œï¼šverbosity æœ‰æ•ˆæ§åˆ¶å›ç­”é•·åº¦")
        elif correlation > 0.4:
            print("  âš ï¸ ä¸­ç­‰æ­£ç›¸é—œï¼šverbosity æœ‰ä¸€å®šå½±éŸ¿")
        elif correlation > 0:
            print("  âŒ å¼±æ­£ç›¸é—œï¼šverbosity å½±éŸ¿ä¸æ˜é¡¯")
        else:
            print("  âŒ ç„¡ç›¸é—œæˆ–è² ç›¸é—œï¼šverbosity æ§åˆ¶å¤±æ•ˆ")

        # é¡¯ç¤ºæ•¸æ“šé»
        print("\næ•¸æ“šé»:")
        print("  Verbosity | Length")
        print("  " + "-" * 20)
        for v, l in sorted(data_points):
            bar = "â–ˆ" * (l // 50)
            print(f"  {v:>8} | {l:>5} {bar}")

    return data_points


def run_interview_stability_test(num_runs: int = 2):
    """åŸ·è¡Œè¨ªè«‡ç©©å®šæ€§æ¸¬è©¦ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼Œä½¿ç”¨æ‰‹å‹•å®šç¾©çš„æ¥µç«¯ personasï¼‰"""
    print("=" * 70)
    print("PPV æ¥µç«¯æ¡ˆä¾‹è¨ªè«‡ç©©å®šæ€§æ¸¬è©¦")
    print("=" * 70)

    # æª¢æŸ¥ API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâŒ éŒ¯èª¤: æœªè¨­å®š OPENAI_API_KEY")
        print("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š OPENAI_API_KEY")
        return None

    test_personas = create_extreme_test_personas()
    results = []

    for persona_name, persona in test_personas:
        print(f"\n{'â”€' * 70}")
        print(f"æ¸¬è©¦ Persona: {persona_name}")
        print(f"ID: {persona['id']}")
        print(f"Big5: O={persona['big5']['openness']}, C={persona['big5']['conscientiousness']}, "
              f"E={persona['big5']['extraversion']}, A={persona['big5']['agreeableness']}, N={persona['big5']['neuroticism']}")
        print(f"é¢¨éšªæ‰¿å—: {persona['risk_profile']['overall']}, æ±ºç­–é¢¨æ ¼: {persona['decision_style']['primary']}")
        print(f"{'â”€' * 70}")

        persona_results = {
            "persona_name": persona_name,
            "persona_id": persona["id"],
            "responses": []
        }

        for q_idx, q_data in enumerate(TEST_QUESTIONS):
            print(f"\nğŸ“ å•é¡Œ {q_idx + 1}: {q_data['question'][:50]}...")

            for run in range(num_runs):
                try:
                    response = interview_vietnam_persona(
                        persona=persona,
                        question=q_data["question"],
                        sub_questions=q_data.get("sub_questions", [])
                    )

                    analysis = analyze_response(response, persona_name)

                    persona_results["responses"].append({
                        "question_idx": q_idx,
                        "run": run + 1,
                        "question": q_data["question"],
                        "response": response,
                        "analysis": analysis
                    })

                    # é¡¯ç¤ºå›ç­”æ‘˜è¦
                    print(f"\n   Run {run + 1}:")
                    print(f"   é•·åº¦: {analysis['length']} chars")
                    preview = response[:200].replace('\n', ' ')
                    print(f"   é è¦½: {preview}...")

                except Exception as e:
                    print(f"\n   âŒ Run {run + 1} éŒ¯èª¤: {str(e)}")
                    persona_results["responses"].append({
                        "question_idx": q_idx,
                        "run": run + 1,
                        "error": str(e)
                    })

        results.append(persona_results)

    # ç”Ÿæˆæ‘˜è¦å ±å‘Š
    print("\n" + "=" * 70)
    print("æ¸¬è©¦çµæœæ‘˜è¦")
    print("=" * 70)

    for persona_result in results:
        print(f"\n{persona_result['persona_name']}:")

        successful_responses = [r for r in persona_result["responses"] if "response" in r]
        if successful_responses:
            avg_length = sum(r["analysis"]["length"] for r in successful_responses) / len(successful_responses)
            emotion_rate = sum(1 for r in successful_responses if r["analysis"]["has_emotion_words"]) / len(successful_responses)
            negative_rate = sum(1 for r in successful_responses if r["analysis"]["has_negative_sentiment"]) / len(successful_responses)

            print(f"   â€¢ æˆåŠŸå›ç­”: {len(successful_responses)}/{len(persona_result['responses'])}")
            print(f"   â€¢ å¹³å‡é•·åº¦: {avg_length:.0f} chars")
            print(f"   â€¢ æƒ…ç·’è¡¨é”ç‡: {emotion_rate:.1%}")
            print(f"   â€¢ è² é¢æƒ…ç·’ç‡: {negative_rate:.1%}")

            # é¡¯ç¤ºä¸€å€‹å®Œæ•´å›ç­”ç¤ºä¾‹
            if successful_responses:
                example = successful_responses[0]
                print(f"\n   ğŸ“„ å›ç­”ç¤ºä¾‹ (å•é¡Œ 1):")
                print(f"   {'â”€' * 50}")
                # æ ¼å¼åŒ–é¡¯ç¤º
                lines = example["response"].split('\n')
                for line in lines[:10]:  # åªé¡¯ç¤ºå‰ 10 è¡Œ
                    print(f"   {line}")
                if len(lines) > 10:
                    print(f"   ... (é‚„æœ‰ {len(lines) - 10} è¡Œ)")

    return results


def compare_persona_responses(results: list):
    """æ¯”è¼ƒä¸åŒ persona å°ç›¸åŒå•é¡Œçš„å›ç­”å·®ç•°"""
    if not results:
        return

    print("\n" + "=" * 70)
    print("è·¨ Persona å›ç­”æ¯”è¼ƒ")
    print("=" * 70)

    # å–æ¯å€‹ persona å°ç¬¬ä¸€å€‹å•é¡Œçš„ç¬¬ä¸€æ¬¡å›ç­”
    first_question_responses = []
    for persona_result in results:
        for r in persona_result["responses"]:
            if r.get("question_idx") == 0 and r.get("run") == 1 and "response" in r:
                first_question_responses.append({
                    "persona": persona_result["persona_name"],
                    "response": r["response"],
                    "analysis": r["analysis"]
                })
                break

    if len(first_question_responses) < 2:
        print("æ²’æœ‰è¶³å¤ çš„å›ç­”é€²è¡Œæ¯”è¼ƒ")
        return

    print(f"\nå°åŒä¸€å•é¡Œçš„å›ç­”å·®ç•°åˆ†æ (å•é¡Œ 1):")
    print(f"{'â”€' * 70}")

    for resp in first_question_responses:
        print(f"\nã€{resp['persona']}ã€‘")
        print(f"   é•·åº¦: {resp['analysis']['length']} chars")
        print(f"   æƒ…ç·’è©: {'âœ“' if resp['analysis']['has_emotion_words'] else 'âœ—'}")
        print(f"   è² é¢æƒ…ç·’: {'âœ“' if resp['analysis']['has_negative_sentiment'] else 'âœ—'}")
        print(f"   ä¸ç¢ºå®šæ€§: {'âœ“' if resp['analysis']['has_uncertainty'] else 'âœ—'}")
        print(f"   è‡ªä¿¡è¡¨é”: {'âœ“' if resp['analysis']['has_confidence'] else 'âœ—'}")

    # è¨ˆç®—å›ç­”é•·åº¦çš„è®Šç•°ä¿‚æ•¸
    lengths = [r["analysis"]["length"] for r in first_question_responses]
    if lengths:
        import statistics
        mean_len = statistics.mean(lengths)
        std_len = statistics.stdev(lengths) if len(lengths) > 1 else 0
        cv = (std_len / mean_len * 100) if mean_len > 0 else 0

        print(f"\nğŸ“Š å›ç­”é•·åº¦çµ±è¨ˆ:")
        print(f"   â€¢ å¹³å‡: {mean_len:.0f} chars")
        print(f"   â€¢ æ¨™æº–å·®: {std_len:.0f} chars")
        print(f"   â€¢ è®Šç•°ä¿‚æ•¸: {cv:.1f}%")

        if cv > 30:
            print(f"   âœ… è®Šç•°ä¿‚æ•¸ > 30%ï¼Œè¡¨ç¤ºä¸åŒ persona æœ‰æ˜é¡¯çš„å›ç­”é¢¨æ ¼å·®ç•°")
        else:
            print(f"   âš ï¸ è®Šç•°ä¿‚æ•¸è¼ƒä½ï¼Œä¸åŒ persona çš„å›ç­”é¢¨æ ¼å¯èƒ½éæ–¼ç›¸ä¼¼")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="PPV æ¥µç«¯æ¡ˆä¾‹è¨ªè«‡æ¸¬è©¦")
    parser.add_argument(
        "--mode", "-m",
        choices=["original", "ppv_driven", "verbosity_gradient", "cross", "diagonal", "correlation", "diversity"],
        default="ppv_driven",
        help="""æ¸¬è©¦æ¨¡å¼:
            original: åŸå§‹æ‰‹å‹•å®šç¾©çš„æ¥µç«¯ personas
            ppv_driven: PPV æ•¸å€¼é©…å‹•çš„æ¥µç«¯æ¸¬è©¦
            verbosity_gradient: verbosity æ¢¯åº¦æ¸¬è©¦ (0â†’100)
            cross: å¤šç¶­åº¦äº¤å‰æ¸¬è©¦
            diagonal: å°è§’æ¥µç«¯æ¸¬è©¦
            correlation: verbosity ç›¸é—œæ€§åˆ†æ
            diversity: å¤šæ¨£æ€§èˆ‡æ¥µç«¯ç¨‹åº¦å…¨é¢åˆ†æ"""
    )
    parser.add_argument(
        "--runs", "-r",
        type=int,
        default=1,
        help="æ¯å€‹ persona æ¸¬è©¦æ¬¡æ•¸ï¼ˆé è¨­ 1ï¼‰"
    )

    args = parser.parse_args()

    print(f"\né¸æ“‡çš„æ¸¬è©¦æ¨¡å¼: {args.mode}")
    print(f"æ¯å€‹ persona æ¸¬è©¦æ¬¡æ•¸: {args.runs}\n")

    if args.mode == "original":
        results = run_interview_stability_test(num_runs=args.runs)
        if results:
            compare_persona_responses(results)

    elif args.mode == "ppv_driven":
        results = run_ppv_driven_test(
            test_type="all_key",
            num_runs=args.runs
        )

    elif args.mode == "verbosity_gradient":
        results = run_ppv_driven_test(
            test_type="verbosity_gradient",
            num_runs=args.runs
        )

    elif args.mode == "cross":
        results = run_ppv_driven_test(
            test_type="cross_dimension",
            num_runs=args.runs
        )

    elif args.mode == "diagonal":
        results = run_ppv_driven_test(
            test_type="diagonal",
            num_runs=args.runs
        )

    elif args.mode == "correlation":
        run_verbosity_correlation_test()

    elif args.mode == "diversity":
        run_diversity_analysis_test()
